#!/bin/bash

CONFIG_NAME="$1"
FUSION_STRATEGY="${2:-concat}"  # é»˜è®¤ä½¿ç”¨concatç­–ç•¥

if [ -z "$CONFIG_NAME" ]; then
    echo "ç”¨æ³•: ./train_ablation.sh CONFIG_NAME [FUSION_STRATEGY]"
    echo "ç¤ºä¾‹: ./train_ablation.sh ablation_input_fusion concat"
    echo "FUSION_STRATEGYå¯é€‰: concat, add, gate"
    exit 1
fi

CONFIG_FILE="model_config/${CONFIG_NAME}.yml"

echo "ğŸ”¬ å¼€å§‹RDTæ¶ˆèå®éªŒè®­ç»ƒ: è¾“å…¥ä¾§è§†è§‰ç‰¹å¾èåˆ"
echo "CONFIG_NAME: $CONFIG_NAME"
echo "CONFIG_FILE: $CONFIG_FILE"
echo "FUSION_STRATEGY: $FUSION_STRATEGY"

# æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if [ ! -f "$CONFIG_FILE" ]; then
    echo "âŒ é…ç½®æ–‡ä»¶ $CONFIG_FILE ä¸å­˜åœ¨!"
    echo "ğŸ“ åˆ›å»ºæ¨¡æ¿é…ç½®æ–‡ä»¶..."
    
    # åˆ›å»ºé…ç½®ç›®å½•
    mkdir -p "model_config"
    
    # åˆ›å»ºæ¶ˆèå®éªŒé…ç½®æ–‡ä»¶
    cat > "$CONFIG_FILE" << EOF
# æ¶ˆèå®éªŒé…ç½®: è¾“å…¥ä¾§è§†è§‰ç‰¹å¾èåˆ
model: $CONFIG_NAME
data_path: training_data/$CONFIG_NAME
checkpoint_path: checkpoints/$CONFIG_NAME
pretrained_model_name_or_path: "../weights/RDT/rdt-1b"
cuda_visible_device: "0,1,2,3"

# è®­ç»ƒè¶…å‚æ•°
train_batch_size: 16
sample_batch_size: 32
max_train_steps: 20000
checkpointing_period: 2500
sample_period: 100
checkpoints_total_limit: 40
learning_rate: 1e-4
dataloader_num_workers: 8
state_noise_snr: 40
gradient_accumulation_steps: 2
lr_scheduler: "constant_with_warmup"
dataset_type: "finetune"

# ğŸ”¬ æ¶ˆèå®éªŒé…ç½®
ablation_study: true
experiment_type: "input_side_visual_fusion"

# ğŸš« ç§»é™¤REPAç›¸å…³ç»„ä»¶
enable_repa_loss: false
enable_critical_annotation: false
enable_soft_routing_repa: false

# âœ… å¤šæ¨¡æ€è§†è§‰ç‰¹å¾é…ç½®
use_dinov2_features: true
dinov2_feature_dim: 1024
use_depth_features: true
depth_feature_dim: 1024
visual_fusion_strategy: "$FUSION_STRATEGY"
EOF
    
    echo "âœ… æ¨¡æ¿é…ç½®æ–‡ä»¶å·²åˆ›å»º: $CONFIG_FILE"
    echo "ğŸ“‹ è¯·æ£€æŸ¥å¹¶ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œç„¶åé‡æ–°è¿è¡Œè„šæœ¬"
    exit 0
fi

# ç¯å¢ƒè®¾ç½®
export NCCL_IB_DISABLE=1
export NCCL_P2P_DISABLE=1
export NCCL_DEBUG=INFO
export TEXT_ENCODER_NAME="google/t5-v1_1-xxl"
export VISION_ENCODER_NAME="../weights/RDT/siglip-so400m-patch14-384"
export PRETRAINED_RDT="/home/deng_xiang/qian_daichao/RoboTwin/policy/weights/RDT/rdt-1b/pytorch_model.bin"
export WANDB_PROJECT="RDT_Ablation_InputFusion"
export WANDB_DEFAULT_RUN_NAME="${CONFIG_NAME}_${FUSION_STRATEGY}"

# è¯»å–é…ç½®çš„è¾…åŠ©å‡½æ•°
read_yaml_config() {
    local file="$1"
    local key="$2"
    if [ -f "scripts/read_yaml.py" ]; then
        python scripts/read_yaml.py "$file" "$key" 2>/dev/null
    else
        # å¤‡ç”¨æ–¹æ¡ˆä½¿ç”¨grep
        grep "^$key:" "$file" | sed "s/^$key: *//" | tr -d '"' | head -1
    fi
}

# ä»é…ç½®æ–‡ä»¶è¯»å–å…³é”®è®¾ç½®
TRAIN_BATCH_SIZE=$(read_yaml_config "$CONFIG_FILE" train_batch_size)
SAMPLE_BATCH_SIZE=$(read_yaml_config "$CONFIG_FILE" sample_batch_size)
MAX_TRAIN_STEPS=$(read_yaml_config "$CONFIG_FILE" max_train_steps)
CHECKPOINTING_PERIOD=$(read_yaml_config "$CONFIG_FILE" checkpointing_period)
SAMPLE_PERIOD=$(read_yaml_config "$CONFIG_FILE" sample_period)
CHECKPOINTS_TOTAL_LIMIT=$(read_yaml_config "$CONFIG_FILE" checkpoints_total_limit)
LR_SCHEDULER=$(read_yaml_config "$CONFIG_FILE" lr_scheduler)
LEARNING_RATE=$(read_yaml_config "$CONFIG_FILE" learning_rate)
DATALOADER_NUM_WORKERS=$(read_yaml_config "$CONFIG_FILE" dataloader_num_workers)
DATASET_TYPE=$(read_yaml_config "$CONFIG_FILE" dataset_type)
STATE_NOISE_SNR=$(read_yaml_config "$CONFIG_FILE" state_noise_snr)
GRAD_ACCUM_STEPS=$(read_yaml_config "$CONFIG_FILE" gradient_accumulation_steps)
OUTPUT_DIR=$(read_yaml_config "$CONFIG_FILE" checkpoint_path)
CUDA_USE=$(read_yaml_config "$CONFIG_FILE" cuda_visible_device)

# æ¶ˆèå®éªŒç‰¹å®šè®¾ç½®
USE_DINOV2=$(read_yaml_config "$CONFIG_FILE" use_dinov2_features)
USE_DEPTH=$(read_yaml_config "$CONFIG_FILE" use_depth_features)
VISUAL_FUSION_STRATEGY=$(read_yaml_config "$CONFIG_FILE" visual_fusion_strategy)

# æ¸…ç†å¼•å·
CUDA_USE=$(echo "$CUDA_USE" | tr -d '"')
OUTPUT_DIR=$(echo "$OUTPUT_DIR" | tr -d '"')
LR_SCHEDULER=$(echo "$LR_SCHEDULER" | tr -d '"')
DATASET_TYPE=$(echo "$DATASET_TYPE" | tr -d '"')
VISUAL_FUSION_STRATEGY=$(echo "$VISUAL_FUSION_STRATEGY" | tr -d '"')

# è®¾ç½®é»˜è®¤å€¼
TRAIN_BATCH_SIZE=${TRAIN_BATCH_SIZE:-16}
SAMPLE_BATCH_SIZE=${SAMPLE_BATCH_SIZE:-32}
MAX_TRAIN_STEPS=${MAX_TRAIN_STEPS:-20000}
CHECKPOINTING_PERIOD=${CHECKPOINTING_PERIOD:-2500}
SAMPLE_PERIOD=${SAMPLE_PERIOD:-100}
CHECKPOINTS_TOTAL_LIMIT=${CHECKPOINTS_TOTAL_LIMIT:-40}
LR_SCHEDULER=${LR_SCHEDULER:-constant_with_warmup}
LEARNING_RATE=${LEARNING_RATE:-1e-4}
DATALOADER_NUM_WORKERS=${DATALOADER_NUM_WORKERS:-8}
DATASET_TYPE=${DATASET_TYPE:-finetune}
GRAD_ACCUM_STEPS=${GRAD_ACCUM_STEPS:-1}
CUDA_USE=${CUDA_USE:-0}
USE_DINOV2=${USE_DINOV2:-true}
USE_DEPTH=${USE_DEPTH:-true}
VISUAL_FUSION_STRATEGY=${VISUAL_FUSION_STRATEGY:-$FUSION_STRATEGY}

# åˆ›å»ºè¾“å‡ºç›®å½•
if [ ! -d "$OUTPUT_DIR" ]; then
    mkdir -p "$OUTPUT_DIR"
    echo "âœ… åˆ›å»ºè¾“å‡ºç›®å½•: $OUTPUT_DIR"
fi

# å¤åˆ¶é…ç½®æ–‡ä»¶åˆ°è¾“å‡ºç›®å½•
cp "$CONFIG_FILE" "$OUTPUT_DIR/training_config.yaml"

export CUDA_VISIBLE_DEVICES=$CUDA_USE

echo ""
echo "ğŸ”§ æ¶ˆèå®éªŒé…ç½®æ€»ç»“:"
echo "   - å®éªŒç±»å‹: è¾“å…¥ä¾§è§†è§‰ç‰¹å¾èåˆ"
echo "   - æ¨¡å‹é…ç½®: $CONFIG_NAME"
echo "   - æ‰¹å¤§å°: $TRAIN_BATCH_SIZE"
echo "   - æœ€å¤§æ­¥æ•°: $MAX_TRAIN_STEPS"
echo "   - å­¦ä¹ ç‡: $LEARNING_RATE"
echo "   - è¾“å‡ºç›®å½•: $OUTPUT_DIR"
echo "   - CUDAè®¾å¤‡: $CUDA_USE"
echo "   - æ•°æ®é›†ç±»å‹: $DATASET_TYPE"
echo ""
echo "ğŸ”¬ æ¶ˆèå®éªŒç‰¹æ€§:"
echo "   - REPAå¯¹é½: å·²ç§»é™¤"
echo "   - DINOv2ç‰¹å¾: $USE_DINOV2"
echo "   - æ·±åº¦ç‰¹å¾: $USE_DEPTH"
echo "   - èåˆç­–ç•¥: $VISUAL_FUSION_STRATEGY"
echo "   - å…³é”®æ—¶é—´æ®µæ ‡æ³¨: å·²ç¦ç”¨"
echo ""

# è®¡ç®—æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
echo "ğŸ“Š è®¡ç®—æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯..."
python -m data.compute_dataset_stat_hdf5 --task_name $CONFIG_NAME

# éªŒè¯å¿…éœ€æ–‡ä»¶
if [ ! -f "$PRETRAINED_RDT" ]; then
    echo "âš ï¸  è­¦å‘Š: é¢„è®­ç»ƒRDTæ¨¡å‹æœªæ‰¾åˆ°: $PRETRAINED_RDT"
    echo "è¯·æ›´æ–°è„šæœ¬ä¸­çš„PRETRAINED_RDTè·¯å¾„ã€‚"
fi

# æ£€æŸ¥main_ablation.pyæ˜¯å¦å­˜åœ¨
if [ ! -f "main_ablation.py" ]; then
    echo "âŒ main_ablation.pyæœªåœ¨å½“å‰ç›®å½•æ‰¾åˆ°!"
    echo "è¯·ç¡®ä¿ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬ã€‚"
    exit 1
fi

# å¯åŠ¨æ¶ˆèå®éªŒè®­ç»ƒ
echo "ğŸƒ å¯åŠ¨æ¶ˆèå®éªŒè®­ç»ƒ..."
echo "ğŸ“ å‘½ä»¤: accelerate launch --main_process_port=28499 main_ablation.py ..."
echo ""

accelerate launch --main_process_port=28499 main_ablation.py \
    --deepspeed="./configs/zero2.json" \
    --pretrained_model_name_or_path="$PRETRAINED_RDT" \
    --pretrained_text_encoder_name_or_path=$TEXT_ENCODER_NAME \
    --pretrained_vision_encoder_name_or_path=$VISION_ENCODER_NAME \
    --output_dir=$OUTPUT_DIR \
    --train_batch_size=$TRAIN_BATCH_SIZE \
    --sample_batch_size=$SAMPLE_BATCH_SIZE \
    --max_train_steps=$MAX_TRAIN_STEPS \
    --checkpointing_period=$CHECKPOINTING_PERIOD \
    --sample_period=$SAMPLE_PERIOD \
    --checkpoints_total_limit=$CHECKPOINTS_TOTAL_LIMIT \
    --lr_scheduler=$LR_SCHEDULER \
    --learning_rate=$LEARNING_RATE \
    --mixed_precision="bf16" \
    --dataloader_num_workers=$DATALOADER_NUM_WORKERS \
    --image_aug \
    --dataset_type=$DATASET_TYPE \
    --state_noise_snr=$STATE_NOISE_SNR \
    --load_from_hdf5 \
    --report_to=wandb \
    --precomp_lang_embed \
    --gradient_accumulation_steps=$GRAD_ACCUM_STEPS \
    --model_config_path=$CONFIG_FILE \
    --CONFIG_NAME=$CONFIG_NAME \
    --config_path="configs/base.yaml"

TRAINING_EXIT_CODE=$?

echo ""
if [ $TRAINING_EXIT_CODE -eq 0 ]; then
    echo "âœ… æ¶ˆèå®éªŒè®­ç»ƒæˆåŠŸå®Œæˆ!"
    echo "ğŸ“ æ¨¡å‹ä¿å­˜åˆ°: $OUTPUT_DIR"
    echo "ğŸ“Š è®­ç»ƒé…ç½®ä¿å­˜åˆ°: $OUTPUT_DIR/training_config.yaml"
    echo "ğŸ“ˆ æŸ¥çœ‹wandbè·å–è®­ç»ƒæŒ‡æ ‡å’Œå¯è§†åŒ–"
    
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
    if [ -f "$OUTPUT_DIR/ablation_study_config.json" ]; then
        echo ""
        echo "ğŸ“‹ æ¶ˆèå®éªŒæœ€ç»ˆç»Ÿè®¡:"
        python -c "
import json
try:
    with open('$OUTPUT_DIR/ablation_study_config.json', 'r') as f:
        config = json.load(f)
        print(f'   - å®éªŒç±»å‹: {config.get(\"experiment_type\", \"N/A\")}')
        print(f'   - REPAå¯¹é½å·²ç§»é™¤: {config.get(\"repa_alignment_removed\", \"N/A\")}')
        visual_features = config.get('visual_features', {})
        print(f'   - SigLIP patches: {visual_features.get(\"siglip_patches\", \"N/A\")}')
        print(f'   - DINOv2 CLS: {visual_features.get(\"dinov2_cls\", \"N/A\")}')
        print(f'   - Depth CLS: {visual_features.get(\"depth_cls\", \"N/A\")}')
        print(f'   - èåˆç­–ç•¥: {config.get(\"fusion_strategy\", \"N/A\")}')
except:
    print('   ç»Ÿè®¡æ–‡ä»¶æœªæ‰¾åˆ°æˆ–æŸåã€‚')
"
    fi
else
    echo "âŒ è®­ç»ƒå¤±è´¥ï¼Œé€€å‡ºä»£ç : $TRAINING_EXIT_CODE"
    echo "ğŸ“ è¯·æ£€æŸ¥ä¸Šæ–¹æ—¥å¿—è·å–é”™è¯¯è¯¦æƒ…"
    exit $TRAINING_EXIT_CODE
fi

echo ""
echo "ğŸ¯ ä¸‹ä¸€æ­¥éª¤:"
echo "   1. è¯„ä¼°æ¶ˆèå®éªŒæ¨¡å‹æ€§èƒ½"
echo "   2. å¯¹æ¯”è¾“å…¥ä¾§èåˆvs REPAå¯¹é½çš„æ•ˆæœ"
echo "   3. åˆ†æä¸åŒè§†è§‰èåˆç­–ç•¥çš„å½±å“"
echo "   4. éªŒè¯å¤šæ¨¡æ€è§†è§‰ç‰¹å¾çš„æœ‰æ•ˆæ€§"
echo "   5. ç”Ÿæˆæ¶ˆèå®éªŒæŠ¥å‘Š"
echo ""