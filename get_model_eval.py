# policy/RDT_repa/get_model_simple.py - ç®€åŒ–ç‰ˆè¯„æµ‹æ¨¡å‹åŠ è½½å™¨

import torch
import yaml
import os
from pathlib import Path
from transformers import AutoTokenizer

# ğŸ”§ å¯¼å…¥åŸå§‹ç»„ä»¶ï¼Œä½†ä½¿ç”¨è¯„æµ‹æ¨¡å¼
from models.rdt_runner import RDTRunner
from models.multimodal_encoder.siglip_encoder import SiglipVisionTower
from models.multimodal_encoder.t5_encoder import T5Embedder


def get_model(usr_args):
    """
    ç®€åŒ–ç‰ˆè¯„æµ‹æ¨¡å‹åŠ è½½å™¨
    
    ç­–ç•¥ï¼š
    1. ä½¿ç”¨åŸå§‹RDTRunnerä½†ç¦ç”¨REPAåŠŸèƒ½
    2. æ™ºèƒ½å¤„ç†ç¼ºå¤±çš„é…ç½®æ–‡ä»¶
    3. æä¾›å¼ºå¥çš„é”™è¯¯å¤„ç†
    """
    print("ğŸ”§ ç®€åŒ–ç‰ˆè¯„æµ‹æ¨¡å¼ï¼šåˆå§‹åŒ–æ¨¡å‹ç»„ä»¶")
    
    # ğŸ”§ å°è¯•è¯»å–é…ç½®æ–‡ä»¶ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨é»˜è®¤å€¼
    def safe_load_config(file_path, default_config):
        """å®‰å…¨åŠ è½½é…ç½®æ–‡ä»¶"""
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                    print(f"âœ… æˆåŠŸè¯»å–é…ç½®: {file_path}")
                    return config
            except Exception as e:
                print(f"âš ï¸  é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {file_path}, é”™è¯¯: {e}")
        else:
            print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        print("ğŸ”§ ä½¿ç”¨é»˜è®¤é…ç½®")
        return default_config
    
    # ğŸ”§ æŸ¥æ‰¾åŸå§‹çš„deploy_policy.ymlé…ç½®
    deploy_config_candidates = [
        'policy/RDT_repa/deploy_policy.yml',
        'policy/RDT_repa/config.yml', 
        './deploy_policy.yml',
        './config.yml',
    ]
    
    config = None
    config_path = None
    
    for candidate in deploy_config_candidates:
        if os.path.exists(candidate):
            config = safe_load_config(candidate, None)
            if config:
                config_path = candidate
                break
    
    # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    if config is None:
        print("ğŸ”§ ä½¿ç”¨ç¡¬ç¼–ç çš„é»˜è®¤é…ç½®")
        config = {
            "common": {
                "state_dim": 14,
                "action_chunk_size": 64,
                "img_history_size": 1,
                "num_cameras": 3,
            },
            "model": {
                "rdt": {
                    "hidden_size": 2048,
                    "depth": 28,
                    "num_heads": 32,
                },
                "lang_token_dim": 4096,
                "img_token_dim": 1536,
                "state_token_dim": 14,
                "lang_adaptor": "linear",
                "img_adaptor": "linear",
                "state_adaptor": "linear",
            },
            "dataset": {
                "tokenizer_max_length": 1024,
            }
        }
    
    # ğŸ”§ æ™ºèƒ½æ£€æŸ¥ç‚¹è·¯å¾„æŸ¥æ‰¾
    checkpoint_id = str(usr_args.get('checkpoint_id', 'unknown'))
    checkpoint_path = None
    
    # æœç´¢å¯èƒ½çš„æ£€æŸ¥ç‚¹ä½ç½®
    checkpoint_search_dirs = [
        'policy/RDT_repa/checkpoints',
        'checkpoints',
        '.',
    ]
    
    for search_dir in checkpoint_search_dirs:
        if not os.path.exists(search_dir):
            continue
            
        # å°è¯•å¤šç§å‘½åæ ¼å¼
        patterns = [
            f"checkpoint-{checkpoint_id}/pytorch_model.bin",
            f"checkpoint-{checkpoint_id}/model.bin", 
            f"checkpoint_{checkpoint_id}.bin",
            f"model_{checkpoint_id}.bin",
            f"{checkpoint_id}/pytorch_model.bin",
        ]
        
        for pattern in patterns:
            candidate = os.path.join(search_dir, pattern)
            if os.path.exists(candidate):
                checkpoint_path = candidate
                print(f"âœ… æ‰¾åˆ°æ£€æŸ¥ç‚¹: {checkpoint_path}")
                break
        
        if checkpoint_path:
            break
    
    # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼ŒæŸ¥æ‰¾ä»»ä½•å¯ç”¨çš„æ£€æŸ¥ç‚¹
    if checkpoint_path is None:
        print("ğŸ” æœç´¢ä»»ä½•å¯ç”¨çš„æ£€æŸ¥ç‚¹æ–‡ä»¶...")
        for search_dir in checkpoint_search_dirs:
            if not os.path.exists(search_dir):
                continue
            
            for root, dirs, files in os.walk(search_dir):
                for file in files:
                    if file in ['pytorch_model.bin', 'model.bin'] or file.endswith('.bin'):
                        candidate = os.path.join(root, file)
                        checkpoint_path = candidate
                        print(f"ğŸ” æ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶: {checkpoint_path}")
                        break
                if checkpoint_path:
                    break
    
    print(f"ğŸ“‹ è¯„æµ‹é…ç½®:")
    print(f"   - æ£€æŸ¥ç‚¹ID: {checkpoint_id}")
    print(f"   - æ£€æŸ¥ç‚¹è·¯å¾„: {checkpoint_path if checkpoint_path else 'æœªæ‰¾åˆ°'}")
    print(f"   - é…ç½®æ–‡ä»¶: {config_path if config_path else 'ä½¿ç”¨é»˜è®¤é…ç½®'}")

    # è®¾å¤‡é…ç½®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    dtype = torch.bfloat16

    # ğŸ”§ ç®€åŒ–æ–‡æœ¬ç¼–ç å™¨é…ç½®
    print("ğŸ“ é…ç½®æ–‡æœ¬ç¼–ç å™¨")
    precomp_lang_embed = usr_args.get('precomp_lang_embed', True)  # é»˜è®¤ä½¿ç”¨é¢„è®¡ç®—
    
    if precomp_lang_embed:
        print("   - ä½¿ç”¨é¢„è®¡ç®—çš„è¯­è¨€åµŒå…¥")
        tokenizer, text_encoder = None, None
    else:
        try:
            print("   - å°è¯•åŠ è½½T5ç¼–ç å™¨")
            text_encoder_paths = [
                'policy/weights/RDT/t5-v1_1-xxl',
                '../weights/RDT/t5-v1_1-xxl',
                './t5-v1_1-xxl',
            ]
            
            text_encoder_path = None
            for path in text_encoder_paths:
                if os.path.exists(path):
                    text_encoder_path = path
                    break
            
            if text_encoder_path:
                text_embedder = T5Embedder(
                    from_pretrained=text_encoder_path,
                    model_max_length=config["dataset"]["tokenizer_max_length"],
                    device=device,
                )
                tokenizer, text_encoder = text_embedder.tokenizer, text_embedder.model
            else:
                raise FileNotFoundError("T5æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨")
                
        except Exception as e:
            print(f"   âš ï¸  T5åŠ è½½å¤±è´¥: {e}")
            print("   - åˆ‡æ¢åˆ°é¢„è®¡ç®—è¯­è¨€åµŒå…¥æ¨¡å¼")
            precomp_lang_embed = True
            tokenizer, text_encoder = None, None

    # ğŸ”§ ç®€åŒ–è§†è§‰ç¼–ç å™¨é…ç½®
    print("ğŸ–¼ï¸  é…ç½®è§†è§‰ç¼–ç å™¨")
    try:
        vision_encoder_paths = [
            'policy/weights/RDT/siglip-so400m-patch14-384',
            '../weights/RDT/siglip-so400m-patch14-384',
            './siglip-so400m-patch14-384',
        ]
        
        vision_encoder_path = None
        for path in vision_encoder_paths:
            if os.path.exists(path):
                vision_encoder_path = path
                break
        
        if vision_encoder_path:
            vision_encoder = SiglipVisionTower(vision_tower=vision_encoder_path, args=None)
            image_processor = vision_encoder.image_processor
            print(f"   âœ… æˆåŠŸåŠ è½½SigLIP: {vision_encoder_path}")
        else:
            raise FileNotFoundError("SigLIPæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨")
            
    except Exception as e:
        print(f"   âš ï¸  SigLIPåŠ è½½å¤±è´¥: {e}")
        print("   ğŸ”§ ä½¿ç”¨è™šæ‹Ÿè§†è§‰ç¼–ç å™¨")
        
        class DummyVisionEncoder:
            def __init__(self):
                self.num_patches = 1024
                self.hidden_size = 1536
                
            class DummyImageProcessor:
                pass
                
            self.image_processor = DummyImageProcessor()
            
            def __call__(self, *args, **kwargs):
                # è¿”å›è™šæ‹Ÿç‰¹å¾
                batch_size = args[0].shape[0] if args else 1
                return torch.randn(batch_size, self.num_patches, self.hidden_size)
        
        vision_encoder = DummyVisionEncoder()
        image_processor = vision_encoder.image_processor

    # ğŸ”§ æ„å»ºRDTæ¨¡å‹ - å…³é”®ï¼šç¦ç”¨REPAåŠŸèƒ½
    print("ğŸ¤– åˆ›å»ºRDTæ¨¡å‹ (ç¦ç”¨REPA)")
    
    img_cond_len = (config["common"]["img_history_size"] * config["common"]["num_cameras"] *
                    getattr(vision_encoder, 'num_patches', 1024))
    
    # ğŸ”§ å…³é”®ï¼šä½¿ç”¨åŸå§‹RDTRunnerä½†ç¦ç”¨æ‰€æœ‰REPAåŠŸèƒ½
    rdt = RDTRunner(
        action_dim=config["common"]["state_dim"],
        pred_horizon=config["common"]["action_chunk_size"],
        config=config["model"],
        lang_token_dim=config["model"]["lang_token_dim"],
        img_token_dim=config["model"]["img_token_dim"],
        state_token_dim=config["model"]["state_token_dim"],
        max_lang_cond_len=config["dataset"]["tokenizer_max_length"],
        img_cond_len=img_cond_len,
        img_pos_embed_config=[
            ("image", (
                config["common"]["img_history_size"],
                config["common"]["num_cameras"],
                -getattr(vision_encoder, 'num_patches', 1024),
            )),
        ],
        lang_pos_embed_config=[
            ("lang", -config["dataset"]["tokenizer_max_length"]),
        ],
        dtype=dtype,
        # ğŸ”§ å…³é”®ï¼šç¦ç”¨æ‰€æœ‰REPAç›¸å…³åŠŸèƒ½
        enable_soft_routing_repa=False,
        soft_routing_repa_weight=0.0,
        use_dinov2_features=False,
        use_depth_features=False,
    )

    # ğŸ”§ æ™ºèƒ½æƒé‡åŠ è½½
    print("âš™ï¸  åŠ è½½é¢„è®­ç»ƒæƒé‡")
    if checkpoint_path and os.path.exists(checkpoint_path):
        try:
            print(f"   ğŸ”§ å¼€å§‹åŠ è½½: {checkpoint_path}")
            checkpoint = torch.load(checkpoint_path, map_location='cpu')
            
            # å¤„ç†ä¸åŒçš„æ£€æŸ¥ç‚¹æ ¼å¼
            if isinstance(checkpoint, dict):
                if 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                else:
                    state_dict = checkpoint
            else:
                state_dict = checkpoint
            
            # ğŸ”§ è¿‡æ»¤æ‰REPAç›¸å…³çš„å‚æ•°
            filtered_state_dict = {}
            skipped_keys = []
            
            repa_keywords = [
                'dual_teacher_model', 'soft_router', 'routing_network',
                'dinov2_to_action_projector', 'depth_to_action_projector',
                'routing_temperature'
            ]
            
            for key, value in state_dict.items():
                # è·³è¿‡REPAç›¸å…³å‚æ•°
                if any(keyword in key for keyword in repa_keywords):
                    skipped_keys.append(key)
                    continue
                
                # æ£€æŸ¥å½¢çŠ¶æ˜¯å¦åŒ¹é…
                if key in rdt.state_dict():
                    if value.shape == rdt.state_dict()[key].shape:
                        filtered_state_dict[key] = value
                    else:
                        print(f"   âš ï¸  å½¢çŠ¶ä¸åŒ¹é…: {key}")
                        skipped_keys.append(key)
                else:
                    skipped_keys.append(key)
            
            # åŠ è½½è¿‡æ»¤åçš„æƒé‡
            missing_keys, unexpected_keys = rdt.load_state_dict(filtered_state_dict, strict=False)
            
            print(f"   âœ… æˆåŠŸåŠ è½½ {len(filtered_state_dict)} ä¸ªå‚æ•°")
            if skipped_keys:
                print(f"   âš ï¸  è·³è¿‡ {len(skipped_keys)} ä¸ªå‚æ•° (REPAç›¸å…³æˆ–å½¢çŠ¶ä¸åŒ¹é…)")
            if missing_keys:
                print(f"   âš ï¸  {len(missing_keys)} ä¸ªå‚æ•°ä¿æŒé»˜è®¤åˆå§‹åŒ–")
            
        except Exception as e:
            print(f"   âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
            print("   ğŸ”§ ä½¿ç”¨é»˜è®¤åˆå§‹åŒ–çš„æƒé‡")
    else:
        print("   âš ï¸  æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤åˆå§‹åŒ–")

    # ç§»åŠ¨åˆ°è®¾å¤‡å¹¶è®¾ç½®è¯„æµ‹æ¨¡å¼
    rdt.to(device, dtype=dtype)
    rdt.eval()
    
    if text_encoder is not None:
        text_encoder.to(device, dtype=dtype)
        text_encoder.eval()
    
    if hasattr(vision_encoder, 'vision_tower') and vision_encoder.vision_tower is not None:
        vision_encoder.vision_tower.to(device, dtype=dtype)
        vision_encoder.vision_tower.eval()

    # ğŸ”§ åˆ›å»ºè¯„æµ‹ä¸“ç”¨ç­–ç•¥åŒ…è£…å™¨
    class SimpleEvalPolicy:
        """ç®€åŒ–ç‰ˆè¯„æµ‹ç­–ç•¥åŒ…è£…å™¨"""
        
        def __init__(self, rdt_model, text_encoder, vision_encoder, tokenizer, image_processor):
            self.rdt = rdt_model
            self.text_encoder = text_encoder
            self.vision_encoder = vision_encoder
            self.tokenizer = tokenizer
            self.image_processor = image_processor
            self.device = device
            self.dtype = dtype
            self.precomp_lang_embed = precomp_lang_embed
            
            print("âœ… ç®€åŒ–ç‰ˆè¯„æµ‹ç­–ç•¥åˆå§‹åŒ–å®Œæˆ")
            print(f"   - æ¨¡å¼: {'é¢„è®¡ç®—è¯­è¨€åµŒå…¥' if precomp_lang_embed else 'T5ç¼–ç å™¨'}")
            print(f"   - REPAåŠŸèƒ½: å·²ç¦ç”¨")
        
        def __call__(self, *args, **kwargs):
            """å…¼å®¹åŸæœ‰è°ƒç”¨æ–¹å¼"""
            return self.predict_action(*args, **kwargs)
        
        def predict_action(self, lang_tokens, lang_attn_mask, img_tokens, state_tokens,
                          action_mask, ctrl_freqs, **kwargs):
            """é¢„æµ‹åŠ¨ä½œ - ç®€åŒ–ç‰ˆæœ¬"""
            with torch.no_grad():
                # ç¡®ä¿è¾“å…¥åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
                lang_tokens = lang_tokens.to(self.device, dtype=self.dtype)
                img_tokens = img_tokens.to(self.device, dtype=self.dtype)
                state_tokens = state_tokens.to(self.device, dtype=self.dtype)
                action_mask = action_mask.to(self.device, dtype=self.dtype)
                
                if lang_attn_mask is not None:
                    lang_attn_mask = lang_attn_mask.to(self.device)
                
                try:
                    # ğŸ”§ è°ƒç”¨RDTè¿›è¡Œçº¯æ¨ç†ï¼Œä¸ä¼ é€’ä»»ä½•REPAç›¸å…³å‚æ•°
                    action_pred = self.rdt.predict_action(
                        lang_tokens=lang_tokens,
                        lang_attn_mask=lang_attn_mask,
                        img_tokens=img_tokens,
                        state_tokens=state_tokens,
                        action_mask=action_mask,
                        ctrl_freqs=ctrl_freqs,
                        # æ˜ç¡®ä¸ä¼ é€’vision_featuresç­‰å‚æ•°
                    )
                    
                    return action_pred
                    
                except Exception as e:
                    print(f"âŒ æ¨ç†è¿‡ç¨‹å‡ºé”™: {e}")
                    # åˆ›å»ºé»˜è®¤è¾“å‡ºä»¥é¿å…ä¸­æ–­
                    batch_size = lang_tokens.shape[0]
                    pred_horizon = getattr(self.rdt, 'pred_horizon', 64)
                    action_dim = getattr(self.rdt, 'action_dim', 14)
                    
                    default_action = torch.zeros(
                        batch_size, pred_horizon, action_dim,
                        device=self.device, dtype=self.dtype
                    )
                    print(f"ğŸ”§ è¿”å›é»˜è®¤åŠ¨ä½œ: {default_action.shape}")
                    return default_action
    
    # åˆ›å»ºç­–ç•¥å®ä¾‹
    policy = SimpleEvalPolicy(rdt, text_encoder, vision_encoder, tokenizer, image_processor)
    
    # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
    total_params = sum(p.numel() for p in rdt.parameters())
    print("ğŸŠ ç®€åŒ–ç‰ˆè¯„æµ‹æ¨¡å‹åŠ è½½å®Œæˆï¼")
    print(f"   - æ€»å‚æ•°é‡: {total_params:,}")
    print(f"   - è®¾å¤‡: {device}")
    print(f"   - æ•°æ®ç±»å‹: {dtype}")
    print(f"   - æ£€æŸ¥ç‚¹çŠ¶æ€: {'å·²åŠ è½½' if checkpoint_path else 'ä½¿ç”¨é»˜è®¤åˆå§‹åŒ–'}")
    print(f"   - REPAåŠŸèƒ½: å·²å®Œå…¨ç¦ç”¨")
    print(f"   - é¢„æœŸæ¨ç†ç¨³å®šæ€§: é«˜")
    
    return policy


def reset_model(policy):
    """é‡ç½®æ¨¡å‹çŠ¶æ€ - ç®€åŒ–ç‰ˆæœ¬"""
    if hasattr(policy, 'rdt'):
        policy.rdt.eval()
    if hasattr(policy, 'text_encoder') and policy.text_encoder is not None:
        policy.text_encoder.eval()
    if hasattr(policy, 'vision_encoder'):
        if hasattr(policy.vision_encoder, 'vision_tower') and policy.vision_encoder.vision_tower is not None:
            policy.vision_encoder.vision_tower.eval()


def eval(task_env, policy, observation):
    """ç®€åŒ–ç‰ˆè¯„æµ‹å‡½æ•°"""
    try:
        # æå–è§‚å¯Ÿä¿¡æ¯
        lang_tokens = observation.get('lang_tokens')
        lang_attn_mask = observation.get('lang_attn_mask')
        img_tokens = observation.get('img_tokens')
        state_tokens = observation.get('state_tokens')
        action_mask = observation.get('action_mask')
        ctrl_freqs = observation.get('ctrl_freqs')
        
        # è°ƒç”¨ç­–ç•¥é¢„æµ‹
        action_pred = policy.predict_action(
            lang_tokens=lang_tokens,
            lang_attn_mask=lang_attn_mask,
            img_tokens=img_tokens,
            state_tokens=state_tokens,
            action_mask=action_mask,
            ctrl_freqs=ctrl_freqs,
        )
        
        return action_pred
        
    except Exception as e:
        print(f"âŒ è¯„æµ‹æ­¥éª¤å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise e


if __name__ == "__main__":
    # æµ‹è¯•ç®€åŒ–ç‰ˆæ¨¡å‹åŠ è½½
    test_args = {
        'checkpoint_id': '10000',
        'precomp_lang_embed': True,  # ä½¿ç”¨é¢„è®¡ç®—ä»¥ç®€åŒ–æµ‹è¯•
    }
    
    print("ğŸ§ª æµ‹è¯•ç®€åŒ–ç‰ˆè¯„æµ‹æ¨¡å‹åŠ è½½")
    try:
        policy = get_model(test_args)
        print("âœ… æµ‹è¯•æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()