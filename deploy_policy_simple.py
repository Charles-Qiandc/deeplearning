# policy/RDT_repa/deploy_policy_simple.py - ä¿æŒåŸæ–‡ä»¶ä½ç½®çš„ç®€åŒ–ç‰ˆ

import os
import sys
import torch
import numpy as np
from pathlib import Path

# ğŸ”§ æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œè¿™æ ·å¯ä»¥å¯¼å…¥åŒç›®å½•ä¸‹çš„models
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# ğŸ¯ ç°åœ¨å¯ä»¥å¯¼å…¥åŒç›®å½•ä¸‹çš„models/rdt_runner_eval_simple.py
from models.rdt_runner_eval_simple import create_simple_eval_runner


class SimpleRDTRepaModel:
    """
    ç®€åŒ–ç‰ˆRDTæ¨¡å‹éƒ¨ç½²ç±»
    """
    
    def __init__(self, config_path=None, checkpoint_path=None):
        self.config_path = config_path
        self.checkpoint_path = checkpoint_path
        self.model = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ”§ SimpleRDTRepaModelåˆå§‹åŒ–ï¼Œè®¾å¤‡: {self.device}")
    
    def load_model(self, usr_args):
        """åŠ è½½æ¨¡å‹"""
        print(f"ğŸ”§ å¼€å§‹åŠ è½½ç®€åŒ–ç‰ˆRDTæ¨¡å‹...")
        
        # ğŸ¯ æ„å»ºcheckpointè·¯å¾„
        if self.checkpoint_path is None:
            # ä»usr_argsæ„å»ºè·¯å¾„
            policy_name = usr_args.get("policy_name", "RDT_repa")
            ckpt_setting = usr_args.get("ckpt_setting", "default")
            checkpoint_id = usr_args.get("checkpoint_id", "latest")
            
            # ğŸ”§ å°è¯•å¤šä¸ªå¯èƒ½çš„checkpointè·¯å¾„
            possible_paths = [
                f"policy/{policy_name}/checkpoints/{ckpt_setting}/checkpoint-{checkpoint_id}/pytorch_model.bin",
                f"checkpoints/{ckpt_setting}/checkpoint-{checkpoint_id}/pytorch_model.bin",
                f"./policy/{policy_name}/checkpoints/{ckpt_setting}/checkpoint-{checkpoint_id}/pytorch_model.bin",
                f"/home/deng_xiang/qian_daichao/RoboTwin/policy/{policy_name}/checkpoints/{ckpt_setting}/checkpoint-{checkpoint_id}/pytorch_model.bin",
            ]
            
            checkpoint_path = None
            for path in possible_paths:
                if os.path.exists(path):
                    checkpoint_path = path
                    break
            
            if checkpoint_path is None:
                print(f"âš ï¸ åœ¨ä»¥ä¸‹è·¯å¾„ä¸­éƒ½æ‰¾ä¸åˆ°checkpoint:")
                for path in possible_paths:
                    print(f"   - {path}")
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°checkpointæ–‡ä»¶")
        else:
            checkpoint_path = self.checkpoint_path
        
        print(f"ğŸ“ ä½¿ç”¨checkpointè·¯å¾„: {checkpoint_path}")
        
        # ğŸ¯ æ¨¡å‹é…ç½®ï¼ˆæ ‡å‡†RDTé…ç½®ï¼‰
        model_config = {
            'action_dim': 128,  # æ ¹æ®ä½ çš„å…·ä½“ä»»åŠ¡è°ƒæ•´
            'pred_horizon': 64,
            'config': {
                'rdt': {
                    'hidden_size': 2048,
                    'depth': 28,
                    'num_heads': 32,
                },
                'lang_adaptor': 'linear',
                'img_adaptor': 'linear',
                'state_adaptor': 'linear',
                'noise_scheduler': {
                    'num_train_timesteps': 1000,
                    'beta_schedule': 'linear',
                    'prediction_type': 'epsilon',
                    'clip_sample': False,
                    'num_inference_timesteps': 50,
                }
            },
            'lang_token_dim': 4096,
            'img_token_dim': 1536,  # SigLIPç‰¹å¾ç»´åº¦
            'state_token_dim': usr_args.get("left_arm_dim", 7) + usr_args.get("right_arm_dim", 7),  # æœºæ¢°è‡‚ç»´åº¦
            'max_lang_cond_len': 1024,
            'img_cond_len': 4096,   # ğŸ¯ æ ‡å‡†SigLIPé•¿åº¦ï¼Œä¸åŒ…å«é¢å¤–ç‰¹å¾
            'dtype': torch.bfloat16,
        }
        
        # ğŸ¯ åˆ›å»ºç®€åŒ–è¯„æµ‹Runner
        self.model = create_simple_eval_runner(
            checkpoint_path=checkpoint_path,
            **model_config
        )
        
        # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        self.model = self.model.to(self.device)
        self.model.eval()
        
        print(f"âœ… ç®€åŒ–ç‰ˆRDTæ¨¡å‹åŠ è½½å®Œæˆ")
        return self.model
    
    def predict(self, observation, model=None):
        """ç®€åŒ–çš„é¢„æµ‹æ¥å£"""
        if model is None:
            model = self.model
            
        if model is None:
            raise ValueError("æ¨¡å‹å°šæœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨load_model")
        
        # ğŸ¯ æå–æ ‡å‡†è¾“å…¥ï¼ˆåªéœ€è¦åŸºç¡€ç‰¹å¾ï¼‰
        lang_tokens = observation.get('lang_tokens')
        lang_attn_mask = observation.get('lang_attn_mask')
        img_tokens = observation.get('img_tokens')
        state_tokens = observation.get('state_tokens')
        action_mask = observation.get('action_mask')
        ctrl_freqs = observation.get('ctrl_freqs')
        
        # ç¡®ä¿æ‰€æœ‰è¾“å…¥éƒ½åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        if lang_tokens is not None:
            lang_tokens = lang_tokens.to(self.device)
        if lang_attn_mask is not None:
            lang_attn_mask = lang_attn_mask.to(self.device)
        if img_tokens is not None:
            img_tokens = img_tokens.to(self.device)
        if state_tokens is not None:
            state_tokens = state_tokens.to(self.device)
        if action_mask is not None:
            action_mask = action_mask.to(self.device)
        if ctrl_freqs is not None:
            ctrl_freqs = ctrl_freqs.to(self.device)
        
        # ğŸ¯ è°ƒç”¨ç®€åŒ–çš„é¢„æµ‹æ¥å£
        with torch.no_grad():
            action_pred = model.predict_action(
                lang_tokens=lang_tokens,
                lang_attn_mask=lang_attn_mask,
                img_tokens=img_tokens,
                state_tokens=state_tokens,
                action_mask=action_mask,
                ctrl_freqs=ctrl_freqs,
            )
        
        return action_pred


# ğŸ¯ å…¨å±€æ¨¡å‹å®ä¾‹
_global_model = None


def get_model_simple(usr_args):
    """ç®€åŒ–ç‰ˆget_modelå‡½æ•°"""
    global _global_model
    
    if _global_model is None:
        print(f"ğŸ”§ é¦–æ¬¡åˆ›å»ºç®€åŒ–ç‰ˆRDTæ¨¡å‹...")
        _global_model = SimpleRDTRepaModel()
        _global_model.load_model(usr_args)
    else:
        print(f"ğŸ”„ é‡ç”¨å·²åˆ›å»ºçš„ç®€åŒ–ç‰ˆRDTæ¨¡å‹")
    
    return _global_model


def eval_simple(TASK_ENV, model, observation):
    """ç®€åŒ–ç‰ˆè¯„æµ‹å‡½æ•°"""
    try:
        # ğŸ¯ ä½¿ç”¨ç®€åŒ–çš„é¢„æµ‹æ¥å£
        action_pred = model.predict(observation)
        
        # å°†é¢„æµ‹ç»“æœåº”ç”¨åˆ°ç¯å¢ƒ
        if action_pred is not None:
            # è½¬æ¢ä¸ºnumpyå¹¶åº”ç”¨åˆ°ç¯å¢ƒ
            if torch.is_tensor(action_pred):
                action_np = action_pred.cpu().numpy()
            else:
                action_np = action_pred
            
            # åº”ç”¨åŠ¨ä½œåˆ°ç¯å¢ƒ
            TASK_ENV.apply_action(action_np)
        else:
            print("âš ï¸ æ¨¡å‹é¢„æµ‹è¿”å›None")
            
    except Exception as e:
        print(f"âŒ è¯„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def reset_model(model):
    """é‡ç½®æ¨¡å‹çŠ¶æ€"""
    # ğŸ¯ ç®€åŒ–ç‰ˆæœ¬ï¼šåªéœ€è¦æ¸…ç†ç¼“å­˜
    if hasattr(model, 'model') and hasattr(model.model, 'eval'):
        model.model.eval()
    
    # æ¸…ç†GPUç¼“å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()


# ğŸ¯ å…¼å®¹æ€§å‡½æ•°
def get_model(usr_args):
    """å…¼å®¹æ€§wrapper"""
    return get_model_simple(usr_args)


def eval(TASK_ENV, model, observation):
    """å…¼å®¹æ€§wrapper"""
    return eval_simple(TASK_ENV, model, observation)


if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•ç®€åŒ–ç‰ˆRDTæ¨¡å‹éƒ¨ç½²")
    
    test_usr_args = {
        'policy_name': 'RDT_repa',
        'ckpt_setting': 'lift_pot_repa_ablation', 
        'checkpoint_id': '10000',
        'left_arm_dim': 7,
        'right_arm_dim': 7,
    }
    
    try:
        model = get_model_simple(test_usr_args)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {type(model)}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
                # policy/RDT_repa/deploy_policy_simple.py - åŸºäºä½ çš„æºä»£ç ä¿®æ”¹çš„ç®€åŒ–ç‰ˆpolicy

import os
import torch
import numpy as np
from pathlib import Path

# ğŸ¯ ä¿®æ”¹ï¼šå¯¼å…¥ç®€åŒ–ç‰ˆRDTRunner
from models.rdt_runner_eval_simple import create_simple_eval_runner


class SimpleRDTRepaModel:
    """
    ç®€åŒ–ç‰ˆRDTæ¨¡å‹éƒ¨ç½²ç±»
    
    æ ¸å¿ƒç‰¹ç‚¹ï¼š
    1. ä½¿ç”¨æ ‡å‡†RDTç»“æ„ï¼ˆæ— REPAï¼Œæ— å¤šæ¨¡æ€èåˆï¼‰
    2. æ™ºèƒ½åŠ è½½æ¶ˆèå®éªŒcheckpoint
    3. ç®€åŒ–çš„æ¨ç†æ¥å£
    """
    
    def __init__(self, config_path=None, checkpoint_path=None):
        self.config_path = config_path
        self.checkpoint_path = checkpoint_path
        self.model = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ”§ SimpleRDTRepaModelåˆå§‹åŒ–ï¼Œè®¾å¤‡: {self.device}")
    
    def load_model(self, usr_args):
        """åŠ è½½æ¨¡å‹"""
        print(f"ğŸ”§ å¼€å§‹åŠ è½½ç®€åŒ–ç‰ˆRDTæ¨¡å‹...")
        
        # ğŸ¯ æ„å»ºcheckpointè·¯å¾„
        if self.checkpoint_path is None:
            # ä»usr_argsæ„å»ºè·¯å¾„
            policy_name = usr_args.get("policy_name", "RDT_repa")
            ckpt_setting = usr_args.get("ckpt_setting", "default")
            checkpoint_id = usr_args.get("checkpoint_id", "latest")
            
            checkpoint_path = f"policy/{policy_name}/checkpoints/{ckpt_setting}/checkpoint-{checkpoint_id}/pytorch_model.bin"
            
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not os.path.exists(checkpoint_path):
                # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
                alternative_paths = [
                    f"checkpoints/{ckpt_setting}/checkpoint-{checkpoint_id}/pytorch_model.bin",
                    f"./policy/{policy_name}/checkpoints/{ckpt_setting}/checkpoint-{checkpoint_id}/pytorch_model.bin",
                ]
                
                for alt_path in alternative_paths:
                    if os.path.exists(alt_path):
                        checkpoint_path = alt_path
                        break
                else:
                    raise FileNotFoundError(f"æ‰¾ä¸åˆ°checkpointæ–‡ä»¶ï¼Œå°è¯•è¿‡çš„è·¯å¾„: {[checkpoint_path] + alternative_paths}")
        else:
            checkpoint_path = self.checkpoint_path
        
        print(f"ğŸ“ ä½¿ç”¨checkpointè·¯å¾„: {checkpoint_path}")
        
        # ğŸ¯ æ¨¡å‹é…ç½®ï¼ˆæ ‡å‡†RDTé…ç½®ï¼‰
        model_config = {
            'action_dim': 128,  # æ ¹æ®ä½ çš„å…·ä½“ä»»åŠ¡è°ƒæ•´
            'pred_horizon': 64,
            'config': {
                'rdt': {
                    'hidden_size': 2048,
                    'depth': 28,
                    'num_heads': 32,
                },
                'lang_adaptor': 'linear',
                'img_adaptor': 'linear',
                'state_adaptor': 'linear',
                'noise_scheduler': {
                    'num_train_timesteps': 1000,
                    'beta_schedule': 'linear',
                    'prediction_type': 'epsilon',
                    'clip_sample': False,
                    'num_inference_timesteps': 50,
                }
            },
            'lang_token_dim': 4096,
            'img_token_dim': 1536,  # SigLIPç‰¹å¾ç»´åº¦
            'state_token_dim': usr_args.get("left_arm_dim", 7) + usr_args.get("right_arm_dim", 7),  # æœºæ¢°è‡‚ç»´åº¦
            'max_lang_cond_len': 1024,
            'img_cond_len': 4096,   # ğŸ¯ æ ‡å‡†SigLIPé•¿åº¦ï¼Œä¸åŒ…å«é¢å¤–ç‰¹å¾
            'dtype': torch.bfloat16,
        }
        
        # ğŸ¯ åˆ›å»ºç®€åŒ–è¯„æµ‹Runner
        self.model = create_simple_eval_runner(
            checkpoint_path=checkpoint_path,
            **model_config
        )
        
        # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        self.model = self.model.to(self.device)
        self.model.eval()
        
        print(f"âœ… ç®€åŒ–ç‰ˆRDTæ¨¡å‹åŠ è½½å®Œæˆ")
        return self.model
    
    def predict(self, observation, model=None):
        """
        ç®€åŒ–çš„é¢„æµ‹æ¥å£
        
        Args:
            observation: ç¯å¢ƒè§‚æµ‹ï¼ŒåŒ…å«lang_tokens, img_tokensç­‰
            model: æ¨¡å‹å®ä¾‹ï¼ˆå…¼å®¹æ€§å‚æ•°ï¼‰
        
        Returns:
            action: é¢„æµ‹çš„åŠ¨ä½œ
        """
        if model is None:
            model = self.model
            
        if model is None:
            raise ValueError("æ¨¡å‹å°šæœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨load_model")
        
        # ğŸ¯ æå–æ ‡å‡†è¾“å…¥ï¼ˆåªéœ€è¦åŸºç¡€ç‰¹å¾ï¼Œä¸éœ€è¦é¢å¤–çš„è§†è§‰ç‰¹å¾ï¼‰
        lang_tokens = observation.get('lang_tokens')  # è¯­è¨€ç‰¹å¾
        lang_attn_mask = observation.get('lang_attn_mask')  # è¯­è¨€æ³¨æ„åŠ›æ©ç 
        img_tokens = observation.get('img_tokens')    # SigLIPå›¾åƒç‰¹å¾
        state_tokens = observation.get('state_tokens')  # çŠ¶æ€ç‰¹å¾
        action_mask = observation.get('action_mask')  # åŠ¨ä½œæ©ç 
        ctrl_freqs = observation.get('ctrl_freqs')    # æ§åˆ¶é¢‘ç‡
        
        # ğŸ¯ æ³¨æ„ï¼šä¸éœ€è¦dinov2_features, depth_featuresç­‰é¢å¤–ç‰¹å¾
        
        # ç¡®ä¿æ‰€æœ‰è¾“å…¥éƒ½åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        if lang_tokens is not None:
            lang_tokens = lang_tokens.to(self.device)
        if lang_attn_mask is not None:
            lang_attn_mask = lang_attn_mask.to(self.device)
        if img_tokens is not None:
            img_tokens = img_tokens.to(self.device)
        if state_tokens is not None:
            state_tokens = state_tokens.to(self.device)
        if action_mask is not None:
            action_mask = action_mask.to(self.device)
        if ctrl_freqs is not None:
            ctrl_freqs = ctrl_freqs.to(self.device)
        
        # ğŸ¯ è°ƒç”¨ç®€åŒ–çš„é¢„æµ‹æ¥å£
        with torch.no_grad():
            action_pred = model.predict_action(
                lang_tokens=lang_tokens,
                lang_attn_mask=lang_attn_mask,
                img_tokens=img_tokens,
                state_tokens=state_tokens,
                action_mask=action_mask,
                ctrl_freqs=ctrl_freqs,
                # ğŸ¯ ä¸ä¼ é€’é¢å¤–çš„è§†è§‰ç‰¹å¾å‚æ•°
            )
        
        return action_pred


# ğŸ¯ å…¨å±€æ¨¡å‹å®ä¾‹
_global_model = None


def get_model_simple(usr_args):
    """
    ç®€åŒ–ç‰ˆget_modelå‡½æ•° - æ›¿ä»£åŸæ¥çš„get_model
    
    Args:
        usr_args: ç”¨æˆ·å‚æ•°ï¼ŒåŒ…å«checkpointä¿¡æ¯ç­‰
    
    Returns:
        SimpleRDTRepaModelå®ä¾‹
    """
    global _global_model
    
    if _global_model is None:
        print(f"ğŸ”§ é¦–æ¬¡åˆ›å»ºç®€åŒ–ç‰ˆRDTæ¨¡å‹...")
        _global_model = SimpleRDTRepaModel()
        _global_model.load_model(usr_args)
    else:
        print(f"ğŸ”„ é‡ç”¨å·²åˆ›å»ºçš„ç®€åŒ–ç‰ˆRDTæ¨¡å‹")
    
    return _global_model


def eval_simple(TASK_ENV, model, observation):
    """
    ç®€åŒ–ç‰ˆè¯„æµ‹å‡½æ•° - æ›¿ä»£åŸæ¥çš„evalå‡½æ•°
    
    Args:
        TASK_ENV: ä»»åŠ¡ç¯å¢ƒ
        model: æ¨¡å‹å®ä¾‹
        observation: ç¯å¢ƒè§‚æµ‹
    """
    try:
        # ğŸ¯ ä½¿ç”¨ç®€åŒ–çš„é¢„æµ‹æ¥å£
        action_pred = model.predict(observation)
        
        # å°†é¢„æµ‹ç»“æœåº”ç”¨åˆ°ç¯å¢ƒ
        if action_pred is not None:
            # è½¬æ¢ä¸ºnumpyå¹¶åº”ç”¨åˆ°ç¯å¢ƒ
            if torch.is_tensor(action_pred):
                action_np = action_pred.cpu().numpy()
            else:
                action_np = action_pred
            
            # åº”ç”¨åŠ¨ä½œåˆ°ç¯å¢ƒ
            TASK_ENV.apply_action(action_np)
        else:
            print("âš ï¸ æ¨¡å‹é¢„æµ‹è¿”å›None")
            
    except Exception as e:
        print(f"âŒ è¯„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def reset_model(model):
    """
    é‡ç½®æ¨¡å‹çŠ¶æ€ - ä¿æŒä¸åŸæ¥å£å…¼å®¹
    
    Args:
        model: æ¨¡å‹å®ä¾‹
    """
    # ğŸ¯ ç®€åŒ–ç‰ˆæœ¬ï¼šåªéœ€è¦æ¸…ç†ç¼“å­˜
    if hasattr(model, 'model') and hasattr(model.model, 'eval'):
        model.model.eval()
    
    # æ¸…ç†GPUç¼“å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()


# ğŸ¯ å…¼å®¹æ€§å‡½æ•°ï¼šå¦‚æœæœ‰å…¶ä»–ä»£ç ä»åœ¨ä½¿ç”¨åŸæ¥çš„å‡½æ•°å
def get_model(usr_args):
    """å…¼å®¹æ€§wrapper"""
    return get_model_simple(usr_args)


def eval(TASK_ENV, model, observation):
    """å…¼å®¹æ€§wrapper"""
    return eval_simple(TASK_ENV, model, observation)


# ğŸ¯ æ¨¡å—çº§åˆ«çš„é…ç½®
MODEL_CONFIG = {
    'type': 'simplified_rdt',
    'description': 'Simplified RDT model for evaluation, compatible with ablation experiment checkpoints',
    'features': [
        'Standard RDT structure',
        'No REPA alignment',
        'No multimodal fusion', 
        'Intelligent checkpoint loading',
        'Automatic dimension adaptation'
    ]
}


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª æµ‹è¯•ç®€åŒ–ç‰ˆRDTæ¨¡å‹éƒ¨ç½²")
    
    test_usr_args = {
        'policy_name': 'RDT_repa',
        'ckpt_setting': 'lift_pot_repa_ablation', 
        'checkpoint_id': '10000',
        'left_arm_dim': 7,
        'right_arm_dim': 7,
    }
    
    try:
        model = get_model_simple(test_usr_args)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {type(model)}")
        
        # åˆ›å»ºæµ‹è¯•è§‚æµ‹
        test_observation = {
            'lang_tokens': torch.randn(1, 256, 4096),
            'lang_attn_mask': torch.ones(1, 256),
            'img_tokens': torch.randn(1, 4096, 1536),
            'state_tokens': torch.randn(1, 1, 14),
            'action_mask': torch.ones(1, 64, 1),
            'ctrl_freqs': torch.tensor([10.0]),
        }
        
        # æµ‹è¯•é¢„æµ‹
        prediction = model.predict(test_observation)
        print(f"âœ… é¢„æµ‹æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {prediction.shape}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()