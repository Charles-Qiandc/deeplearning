# agilex_precise_critical_annotator.py

import os
import numpy as np
import h5py
import fnmatch
from typing import Tuple, Dict
from scipy.signal import savgol_filter
from scipy.ndimage import binary_dilation


class AgilexForwardKinematics:
    """
    AgilexåŒè‡‚æœºå™¨äººæ­£è¿åŠ¨å­¦è®¡ç®—å™¨
    åŸºäºå®é™…URDFå‚æ•°å’Œ14ç»´qposæ ¼å¼ï¼š[å·¦è‡‚6å…³èŠ‚+å¤¹çˆª, å³è‡‚6å…³èŠ‚+å¤¹çˆª]
    """
    
    def __init__(self):
        """åŸºäºä½ çš„URDFæ–‡ä»¶é…ç½®DHå‚æ•°"""
        
        # ä»URDFåˆ†æå¾—åˆ°çš„å‰è‡‚DHå‚æ•° (front-left arm)
        # åŸºäºfl_joint1-6çš„é…ç½®
        self.left_dh_params = np.array([
            # [a,     alpha,    d,      theta_offset]
            [0.025,   0,       0.058,   0],          # fl_joint1 (base)
            [-0.264,  -np.pi,  0.0045,  -np.pi/2],  # fl_joint2 -> fl_joint3
            [0.246,   0,      -0.06,    0],          # fl_joint3 -> fl_joint4  
            [0.068,   0,      -0.085,   -np.pi/2],  # fl_joint4 -> fl_joint5
            [0.031,   -np.pi,  0.085,   0],          # fl_joint5 -> fl_joint6
            [0.085,   0,       0.001,   0],          # fl_joint6 -> æœ«ç«¯
        ])
        
        # å³è‡‚DHå‚æ•° (front-right arm)
        # åŸºäºfr_joint1-6çš„é…ç½®ï¼Œä¸å·¦è‡‚é•œåƒ
        self.right_dh_params = np.array([
            [0.025,   0,       0.058,   0],          # fr_joint1 (base)
            [-0.264,  -np.pi,  0.0045,  -np.pi/2],  # fr_joint2 -> fr_joint3
            [0.246,   0,      -0.06,    0],          # fr_joint3 -> fr_joint4
            [0.068,   0,      -0.085,   -np.pi/2],  # fr_joint4 -> fr_joint5
            [0.031,   -np.pi,  0.085,   0],          # fr_joint5 -> fr_joint6
            [0.085,   0,       0.001,   0],          # fr_joint6 -> æœ«ç«¯
        ])
        
        # å·¦å³è‡‚åŸºåº§ä½ç½®åç§»ï¼ˆåŸºäºURDFä¸­çš„jointä½ç½®ï¼‰
        self.left_base_offset = np.array([0.2305, 0.297, 0.782])   # fl_base_jointä½ç½®
        self.right_base_offset = np.array([0.2315, -0.3063, 0.781]) # fr_base_jointä½ç½®
        
    def dh_transform(self, a, alpha, d, theta):
        """æ ‡å‡†DHå˜æ¢çŸ©é˜µ"""
        ct, st = np.cos(theta), np.sin(theta)
        ca, sa = np.cos(alpha), np.sin(alpha)
        
        return np.array([
            [ct,    -st*ca,  st*sa,   a*ct],
            [st,    ct*ca,   -ct*sa,  a*st], 
            [0,     sa,      ca,      d],
            [0,     0,       0,       1]
        ])
    
    def compute_forward_kinematics(self, joint_angles, dh_params, base_offset):
        """è®¡ç®—å•è‡‚æ­£è¿åŠ¨å­¦"""
        T = np.eye(4)
        T[:3, 3] = base_offset  # è®¾ç½®åŸºåº§åç§»
        
        for i, (a, alpha, d, theta_offset) in enumerate(dh_params):
            if i < len(joint_angles):
                theta = joint_angles[i] + theta_offset
                T_i = self.dh_transform(a, alpha, d, theta)
                T = T @ T_i
        
        return T[:3, 3]  # è¿”å›ä½ç½®
    
    def compute_end_effector_positions(self, qpos_trajectory: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        ä»qposè½¨è¿¹è®¡ç®—åŒè‡‚æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®
        
        Args:
            qpos_trajectory: (T, 14) å…³èŠ‚è§’åº¦è½¨è¿¹
                æ ¼å¼ï¼š[å·¦è‡‚6å…³èŠ‚, å·¦å¤¹çˆª, å³è‡‚6å…³èŠ‚, å³å¤¹çˆª]
                
        Returns:
            left_ee_positions: (T, 3) å·¦è‡‚æœ«ç«¯ä½ç½®
            right_ee_positions: (T, 3) å³è‡‚æœ«ç«¯ä½ç½®
        """
        T = qpos_trajectory.shape[0]
        left_ee_positions = np.zeros((T, 3))
        right_ee_positions = np.zeros((T, 3))
        
        for t in range(T):
            # æå–å…³èŠ‚è§’åº¦ï¼ˆè·³è¿‡å¤¹çˆªï¼‰
            left_joints = qpos_trajectory[t, :6]      # å‰6ä¸ªå…³èŠ‚
            right_joints = qpos_trajectory[t, 7:13]   # ç¬¬8-13ä¸ªå…³èŠ‚
            
            # è®¡ç®—æœ«ç«¯ä½ç½®
            left_ee_positions[t] = self.compute_forward_kinematics(
                left_joints, self.left_dh_params, self.left_base_offset)
            
            right_ee_positions[t] = self.compute_forward_kinematics(
                right_joints, self.right_dh_params, self.right_base_offset)
                
        return left_ee_positions, right_ee_positions


class AgilexCriticalAnnotator:
    """
    Agilexæœºå™¨äººå…³é”®æ—¶é—´æ®µæ ‡æ³¨å™¨
    åŸºäºåŒè‡‚æœ«ç«¯æ‰§è¡Œå™¨é€Ÿåº¦çš„å…³é”®æ—¶é—´æ®µæ£€æµ‹
    """
    
    def __init__(self, 
                 velocity_threshold: float = 0.01,
                 expand_steps: int = 3,
                 smooth: bool = True):
        """
        Args:
            velocity_threshold: é€Ÿåº¦é˜ˆå€¼ï¼Œä¸¤è‡‚éƒ½ä½äºæ­¤å€¼è§†ä¸ºå…³é”®æ—¶é—´æ®µ
            expand_steps: å…³é”®æ®µå‰åæ‰©å±•æ­¥æ•°
            smooth: æ˜¯å¦å¹³æ»‘é€Ÿåº¦æ›²çº¿
        """
        self.velocity_threshold = velocity_threshold
        self.expand_steps = expand_steps
        self.smooth = smooth
        
        # åˆå§‹åŒ–æ­£è¿åŠ¨å­¦è®¡ç®—å™¨
        self.fk_calculator = AgilexForwardKinematics()
        
    def compute_velocity(self, trajectory: np.ndarray) -> np.ndarray:
        """è®¡ç®—è½¨è¿¹é€Ÿåº¦ï¼ˆæ¬§æ°èŒƒæ•°ï¼‰"""
        # ç›¸é‚»å¸§å·®åˆ†
        diff = np.diff(trajectory, axis=0, prepend=trajectory[0:1])
        velocity = np.linalg.norm(diff, axis=-1)
        
        # å¹³æ»‘å¤„ç†
        if self.smooth and len(velocity) > 5:
            try:
                window_length = min(5, len(velocity) // 2 * 2 + 1)
                velocity = savgol_filter(velocity, window_length, 3)
            except:
                # é™çº§åˆ°ç®€å•å¹³æ»‘
                velocity = np.convolve(velocity, np.ones(3)/3, mode='same')
        
        return velocity
    
    def annotate(self, qpos_trajectory: np.ndarray) -> Tuple[np.ndarray, Dict]:
        """
        ä»qposè½¨è¿¹æ ‡æ³¨å…³é”®æ—¶é—´æ®µ
        
        Args:
            qpos_trajectory: (T, 14) å…³èŠ‚è§’åº¦è½¨è¿¹
            
        Returns:
            critical_labels: (T,) å…³é”®æ—¶é—´æ®µæ ‡ç­¾ï¼Œ1è¡¨ç¤ºå…³é”®ï¼Œ0è¡¨ç¤ºéå…³é”®
            analysis_info: åˆ†æä¿¡æ¯å­—å…¸
        """
        # 1. è®¡ç®—æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®
        left_ee_pos, right_ee_pos = self.fk_calculator.compute_end_effector_positions(qpos_trajectory)
        
        # 2. è®¡ç®—é€Ÿåº¦
        left_velocity = self.compute_velocity(left_ee_pos)
        right_velocity = self.compute_velocity(right_ee_pos)
        
        # 3. åŒè‡‚éƒ½ä½é€Ÿæ—¶æ ‡è®°ä¸ºå…³é”®æ—¶é—´æ®µ
        left_low_speed = left_velocity < self.velocity_threshold
        right_low_speed = right_velocity < self.velocity_threshold
        critical_mask = left_low_speed & right_low_speed
        
        # 4. æ‰©å±•å…³é”®åŒºåŸŸ
        if self.expand_steps > 0:
            structure = np.ones(2 * self.expand_steps + 1)
            critical_mask = binary_dilation(critical_mask, structure=structure)
        
        # 5. å¼ºåˆ¶èµ·å§‹å’Œç»“æŸä¸ºå…³é”®æ—¶é—´æ®µ
        critical_mask[0] = True
        critical_mask[-1] = True
        
        # 6. è½¬æ¢ä¸º0/1æ ‡ç­¾
        critical_labels = critical_mask.astype(int)
        
        # 7. è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        T = len(critical_labels)
        critical_count = np.sum(critical_labels)
        
        analysis_info = {
            'left_velocity': left_velocity,
            'right_velocity': right_velocity,
            'left_ee_positions': left_ee_pos,
            'right_ee_positions': right_ee_pos,
            'statistics': {
                'total_steps': T,
                'critical_steps': int(critical_count),
                'critical_ratio': float(critical_count / T),
                'velocity_threshold': self.velocity_threshold,
                'left_avg_velocity': float(np.mean(left_velocity)),
                'right_avg_velocity': float(np.mean(right_velocity)),
                'left_max_velocity': float(np.max(left_velocity)),
                'right_max_velocity': float(np.max(right_velocity)),
            }
        }
        
        return critical_labels, analysis_info


def process_hdf5_file(file_path: str, velocity_threshold: float = 0.01) -> Dict:
    """
    å¤„ç†å•ä¸ªHDF5æ–‡ä»¶
    
    Args:
        file_path: HDF5æ–‡ä»¶è·¯å¾„
        velocity_threshold: é€Ÿåº¦é˜ˆå€¼
        
    Returns:
        ç»“æœå­—å…¸ï¼ŒåŒ…å«critical_labelså’Œåˆ†æä¿¡æ¯
    """
    annotator = AgilexCriticalAnnotator(velocity_threshold=velocity_threshold)
    
    try:
        with h5py.File(file_path, 'r') as f:
            qpos = f['observations']['qpos'][:]
            
            # è·³è¿‡åˆå§‹é™æ­¢æ­¥éª¤
            qpos_delta = np.abs(qpos - qpos[0:1])
            moving_indices = np.where(np.any(qpos_delta > 1e-3, axis=1))[0]
            
            if len(moving_indices) > 0:
                start_idx = max(0, moving_indices[0] - 1)
                qpos_active = qpos[start_idx:]
            else:
                qpos_active = qpos
                start_idx = 0
            
            # æ‰§è¡Œæ ‡æ³¨
            critical_labels, analysis_info = annotator.annotate(qpos_active)
            
            # å¦‚æœè·³è¿‡äº†æ­¥éª¤ï¼Œè°ƒæ•´æ ‡ç­¾é•¿åº¦
            if start_idx > 0:
                full_labels = np.zeros(len(qpos), dtype=int)
                full_labels[start_idx:] = critical_labels
                critical_labels = full_labels
            
            return {
                'file_path': file_path,
                'critical_labels': critical_labels,
                'analysis_info': analysis_info,
                'success': True
            }
            
    except Exception as e:
        return {
            'file_path': file_path,
            'error': str(e),
            'success': False
        }


def batch_process_dataset(data_dir: str = None, 
                         velocity_threshold: float = 0.01,
                         max_files: int = 10) -> Dict:
    """
    æ‰¹é‡å¤„ç†æ•°æ®é›†
    
    Returns:
        åŒ…å«æ‰€æœ‰ç»“æœçš„å­—å…¸
    """
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ•°æ®ç›®å½•ï¼Œè‡ªåŠ¨æœç´¢
    if data_dir is None:
        possible_dirs = [
            "processed_data/adjust_bottle",
            "../processed_data/adjust_bottle", 
            "../../processed_data/adjust_bottle",
            "processed_data",
            "../processed_data",
            "../../processed_data",
        ]
        
        for d in possible_dirs:
            if os.path.exists(d):
                data_dir = d
                print(f"ğŸ” è‡ªåŠ¨æ‰¾åˆ°æ•°æ®ç›®å½•: {data_dir}")
                break
        
        if data_dir is None:
            print("âŒ æœªæ‰¾åˆ°æ•°æ®ç›®å½•ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®š --data_dir")
            return {'results': [], 'successful_count': 0, 'total_count': 0}
    
    # æŸ¥æ‰¾HDF5æ–‡ä»¶
    hdf5_files = []
    for root, dirs, files in os.walk(data_dir):
        for filename in fnmatch.filter(files, "*.hdf5"):
            hdf5_files.append(os.path.join(root, filename))
            if len(hdf5_files) >= max_files:
                break
        if len(hdf5_files) >= max_files:
            break
    
    print(f"æ‰¾åˆ° {len(hdf5_files)} ä¸ªHDF5æ–‡ä»¶ï¼Œå¤„ç†å‰ {max_files} ä¸ª")
    
    results = []
    for i, file_path in enumerate(hdf5_files[:max_files]):
        print(f"å¤„ç† {i+1}/{max_files}: {os.path.basename(file_path)}")
        
        result = process_hdf5_file(file_path, velocity_threshold)
        results.append(result)
        
        if result['success']:
            stats = result['analysis_info']['statistics']
            print(f"  âœ… å…³é”®æ¯”ä¾‹: {stats['critical_ratio']:.3f}")
        else:
            print(f"  âŒ å¤±è´¥: {result['error']}")
    
    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    successful_results = [r for r in results if r['success']]
    if successful_results:
        critical_ratios = [r['analysis_info']['statistics']['critical_ratio'] 
                          for r in successful_results]
        avg_ratio = np.mean(critical_ratios)
        print(f"\næ€»ä½“ç»Ÿè®¡: å¹³å‡å…³é”®æ¯”ä¾‹ {avg_ratio:.3f}")
    
    return {
        'results': results,
        'successful_count': len(successful_results),
        'total_count': len(results),
        'config': {
            'velocity_threshold': velocity_threshold,
            'data_dir': data_dir
        }
    }


def create_routing_labels_for_training(batch_results: Dict, save_path: str = "agilex_routing_labels.npy"):
    """
    ä¸ºè®­ç»ƒåˆ›å»ºè·¯ç”±æ ‡ç­¾æ•°æ®é›†
    
    Args:
        batch_results: batch_process_datasetçš„è¿”å›ç»“æœ
        save_path: ä¿å­˜è·¯å¾„
    """
    routing_dataset = {
        'file_paths': [],
        'critical_labels': [],
        'episode_lengths': [],
        'critical_ratios': [],
        'config': batch_results['config']
    }
    
    for result in batch_results['results']:
        if result['success']:
            routing_dataset['file_paths'].append(result['file_path'])
            routing_dataset['critical_labels'].append(result['critical_labels'])
            routing_dataset['episode_lengths'].append(len(result['critical_labels']))
            routing_dataset['critical_ratios'].append(
                result['analysis_info']['statistics']['critical_ratio']
            )
    
    # ä¿å­˜
    np.save(save_path, routing_dataset, allow_pickle=True)
    print(f"è·¯ç”±æ ‡ç­¾æ•°æ®é›†å·²ä¿å­˜åˆ°: {save_path}")
    print(f"åŒ…å« {len(routing_dataset['file_paths'])} ä¸ªepisodeçš„æ ‡æ³¨")
    
    return routing_dataset


def quick_test():
    """å¿«é€Ÿæµ‹è¯•åŠŸèƒ½"""
    print("ğŸ§ª Agilexå…³é”®æ—¶é—´æ®µæ ‡æ³¨å™¨å¿«é€Ÿæµ‹è¯•")
    print("=" * 40)
    
    # æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶ - æ‰©å±•æœç´¢è·¯å¾„
    test_files = []
    search_paths = [
        "processed_data",           # å½“å‰ç›®å½•
        "../processed_data",        # ä¸Šçº§ç›®å½•
        "../../processed_data",     # ä¸Šä¸Šçº§ç›®å½•
        "../processed_data/adjust_bottle",  # å…·ä½“è·¯å¾„
        "../../processed_data/adjust_bottle",
        ".",                        # å½“å‰ç›®å½•çš„æ‰€æœ‰å­ç›®å½•
    ]
    
    print("ğŸ” æœç´¢HDF5æ–‡ä»¶...")
    for search_path in search_paths:
        if os.path.exists(search_path):
            print(f"æ£€æŸ¥è·¯å¾„: {search_path}")
            for root, dirs, files in os.walk(search_path):
                for file in files:
                    if file.endswith(".hdf5"):
                        full_path = os.path.join(root, file)
                        test_files.append(full_path)
                        print(f"  æ‰¾åˆ°: {full_path}")
                        if len(test_files) >= 2:
                            break
                if len(test_files) >= 2:
                    break
        if len(test_files) >= 2:
            break
    
    if not test_files:
        print("âŒ æœªæ‰¾åˆ°HDF5æµ‹è¯•æ–‡ä»¶")
        print("è¯·ç¡®è®¤ä»¥ä¸‹è·¯å¾„ä¸­å­˜åœ¨.hdf5æ–‡ä»¶:")
        for path in search_paths:
            abs_path = os.path.abspath(path)
            exists = "âœ…" if os.path.exists(path) else "âŒ"
            print(f"  {exists} {abs_path}")
        
        # æç¤ºç”¨æˆ·æ‰‹åŠ¨æŒ‡å®šè·¯å¾„
        print("\nğŸ’¡ å¦‚æœæ–‡ä»¶åœ¨å…¶ä»–ä½ç½®ï¼Œè¯·ä½¿ç”¨:")
        print("python critical_timestep_annotator.py --data_dir=/path/to/your/hdf5/files")
        return
    
    print(f"\nğŸ“ ä½¿ç”¨æµ‹è¯•æ–‡ä»¶: {test_files[0]}")
    
    # æµ‹è¯•ä¸åŒé˜ˆå€¼
    thresholds = [0.005, 0.01, 0.02]
    print("\né˜ˆå€¼æµ‹è¯•ç»“æœ:")
    print("é˜ˆå€¼   | å…³é”®æ¯”ä¾‹ | å»ºè®®")
    print("-" * 25)
    
    for threshold in thresholds:
        result = process_hdf5_file(test_files[0], threshold)
        if result['success']:
            ratio = result['analysis_info']['statistics']['critical_ratio']
            
            if ratio > 0.8:
                suggestion = "è¿‡é«˜"
            elif ratio < 0.2:
                suggestion = "è¿‡ä½"
            else:
                suggestion = "âœ…åˆç†"
                
            print(f"{threshold:5.3f} | {ratio:7.3f} | {suggestion}")
        else:
            print(f"{threshold:5.3f} | é”™è¯¯   | {result['error']}")
    
    print("\nâœ… å¿«é€Ÿæµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) == 1:
        # æ— å‚æ•°æ—¶è¿è¡Œå¿«é€Ÿæµ‹è¯•
        quick_test()
    else:
        # å‘½ä»¤è¡Œå‚æ•°å¤„ç†
        import argparse
        parser = argparse.ArgumentParser(description="Agilexå…³é”®æ—¶é—´æ®µæ ‡æ³¨å™¨")
        parser.add_argument("--data_dir", default="processed_data/adjust_bottle")
        parser.add_argument("--velocity_threshold", type=float, default=0.01)
        parser.add_argument("--max_files", type=int, default=10)
        parser.add_argument("--save_labels", default="agilex_routing_labels.npy")
        
        args = parser.parse_args()
        
        # æ‰¹é‡å¤„ç†
        batch_results = batch_process_dataset(
            args.data_dir, args.velocity_threshold, args.max_files
        )
        
        # åˆ›å»ºè®­ç»ƒç”¨çš„è·¯ç”±æ ‡ç­¾
        create_routing_labels_for_training(batch_results, args.save_labels)