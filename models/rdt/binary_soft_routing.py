
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Optional, Tuple
import numpy as np


class BinaryLabelSoftRouter(nn.Module):
    """
    åŸºäºå…³é”®æ—¶é—´æ®µäºŒå…ƒæ ‡ç­¾çš„è½¯è·¯ç”±æƒé‡åˆ†é…å™¨ - ä¿®å¤view/reshapeé”™è¯¯
    """
    
    def __init__(self,
                 action_dim: int = 2048,
                 hidden_dim: int = 256,
                 # åŸºç¡€æƒé‡é…ç½®
                 critical_global_weight: float = 0.25,
                 critical_depth_weight: float = 0.75,
                 non_critical_global_weight: float = 0.75,
                 non_critical_depth_weight: float = 0.25,
                 # å¾®è°ƒå’Œå¹³æ»‘å‚æ•°
                 enable_neural_adjustment: bool = True,
                 adjustment_strength: float = 0.1,
                 temporal_smoothing: float = 0.9,
                 temperature: float = 1.0):
        super().__init__()
        
        self.action_dim = action_dim
        self.hidden_dim = hidden_dim
        
        # åŸºç¡€æƒé‡é…ç½®
        self.critical_global_weight = critical_global_weight
        self.critical_depth_weight = critical_depth_weight
        self.non_critical_global_weight = non_critical_global_weight
        self.non_critical_depth_weight = non_critical_depth_weight
        
        # ç¡®ä¿æƒé‡å’Œä¸º1
        assert abs(critical_global_weight + critical_depth_weight - 1.0) < 1e-6
        assert abs(non_critical_global_weight + non_critical_depth_weight - 1.0) < 1e-6
        
        # å¾®è°ƒå’Œå¹³æ»‘å‚æ•°
        self.enable_neural_adjustment = enable_neural_adjustment
        self.adjustment_strength = adjustment_strength
        self.temporal_smoothing = temporal_smoothing
        self.temperature = nn.Parameter(torch.tensor(temperature))
        
        # ğŸ”§ ä¿®å¤ï¼šç¥ç»ç½‘ç»œå¾®è°ƒå™¨
        if enable_neural_adjustment:
            self.weight_adjuster = nn.Sequential(
                nn.Linear(action_dim, hidden_dim),
                nn.LayerNorm(hidden_dim),
                nn.GELU(),
                nn.Dropout(0.1),
                nn.Linear(hidden_dim, hidden_dim // 2),
                nn.LayerNorm(hidden_dim // 2),
                nn.GELU(),
                nn.Linear(hidden_dim // 2, 2),  # è¾“å‡ºè°ƒæ•´å€¼ [global_adj, depth_adj]
                nn.Tanh()  # è¾“å‡ºèŒƒå›´ [-1, 1]
            )
            self._initialize_adjuster()
        
        # å­˜å‚¨ä¸Šä¸€æ—¶é—´æ­¥çš„æƒé‡ç”¨äºå¹³æ»‘
        self.register_buffer('prev_weights', torch.zeros(1, 1, 2))
        
    def _initialize_adjuster(self):
        """åˆå§‹åŒ–æƒé‡å¾®è°ƒå™¨"""
        for module in self.weight_adjuster:
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight, gain=0.1)  # å°åˆå§‹åŒ–
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
    
    def get_base_weights(self, critical_labels: torch.Tensor) -> torch.Tensor:
        """
        æ ¹æ®äºŒå…ƒæ ‡ç­¾è·å–åŸºç¡€æƒé‡ - ä½¿ç”¨æŸ¥æ‰¾è¡¨æ–¹æ³•ï¼ˆæœ€å®‰å…¨ï¼‰
        
        Args:
            critical_labels: (B, T) å…³é”®æ—¶é—´æ®µæ ‡ç­¾ï¼Œ0/1
            
        Returns:
            base_weights: (B, T, 2) åŸºç¡€æƒé‡ [global_weight, depth_weight]
        """
        B, T = critical_labels.shape
        device = critical_labels.device
        dtype = critical_labels.dtype if critical_labels.dtype.is_floating_point else torch.float32
        
        # ğŸ”§ ä½¿ç”¨æŸ¥æ‰¾è¡¨æ–¹æ³•ï¼ˆæœ€å®‰å…¨ï¼Œé¿å…æ©ç ç´¢å¼•é—®é¢˜ï¼‰
        weight_lookup = torch.tensor([
            [self.non_critical_global_weight, self.non_critical_depth_weight],  # label=0
            [self.critical_global_weight, self.critical_depth_weight]           # label=1
        ], device=device, dtype=dtype)  # (2, 2)
        
        # ç›´æ¥ç´¢å¼•è·å–æƒé‡
        weights = weight_lookup[critical_labels.long()]  # (B, T, 2)
        
        # éªŒè¯æƒé‡å’Œä¸º1
        weight_sums = weights.sum(dim=-1)  # (B, T)
        assert torch.allclose(weight_sums, torch.ones_like(weight_sums), atol=1e-6), \
            f"æƒé‡å’Œä¸ä¸º1: {weight_sums.unique()}"
        
        return weights
    
    def apply_neural_adjustment(self, 
                              base_weights: torch.Tensor, 
                              action_tokens: torch.Tensor) -> torch.Tensor:
        """
        ğŸ”§ ä¿®å¤ç‰ˆï¼šä½¿ç”¨ç¥ç»ç½‘ç»œå¾®è°ƒæƒé‡ - ä¿®å¤view/reshapeé—®é¢˜
        """
        if not self.enable_neural_adjustment:
            return base_weights
        
        B, T, _ = action_tokens.shape
        
        # ğŸ”§ ç¡®ä¿å½¢çŠ¶æ­£ç¡®
        assert base_weights.shape == (B, T, 2), f"åŸºç¡€æƒé‡å½¢çŠ¶é”™è¯¯: {base_weights.shape}, æœŸæœ›: ({B}, {T}, 2)"
        assert action_tokens.shape == (B, T, self.action_dim), f"åŠ¨ä½œtokenå½¢çŠ¶é”™è¯¯: {action_tokens.shape}"
        
        try:
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ .reshape() è€Œä¸æ˜¯ .view()ï¼Œå¹¶ç¡®ä¿å¼ é‡è¿ç»­æ€§
            # æ–¹æ³•1ï¼šä½¿ç”¨ contiguous() + reshape()
            flat_tokens = action_tokens.contiguous().reshape(B * T, -1)
            
            # è®¡ç®—è°ƒæ•´å€¼
            adjustments = self.weight_adjuster(flat_tokens)  # (B*T, 2)
            adjustments = adjustments.reshape(B, T, 2)       # (B, T, 2)
            
        except Exception as e:
            print(f"âŒ reshapeæ–¹æ³•å¤±è´¥: {e}")
            try:
                # ğŸ”§ å¤‡é€‰æ–¹æ³•ï¼šä½¿ç”¨permute + flatten + unflatten
                # é‡æ–°æ’åˆ—ç»´åº¦ç¡®ä¿è¿ç»­æ€§
                tokens_permuted = action_tokens.permute(0, 1, 2).contiguous()  # ç¡®ä¿è¿ç»­
                flat_tokens = tokens_permuted.view(B * T, self.action_dim)
                
                adjustments = self.weight_adjuster(flat_tokens)  # (B*T, 2)
                adjustments = adjustments.view(B, T, 2)          # (B, T, 2)
                
            except Exception as e2:
                print(f"âŒ å¤‡é€‰æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}")
                # ğŸ”§ æœ€ç»ˆå¤‡é€‰ï¼šé€ä¸ªå¤„ç†
                adjustments = torch.zeros(B, T, 2, device=action_tokens.device, dtype=action_tokens.dtype)
                for b in range(B):
                    for t in range(T):
                        token = action_tokens[b, t, :]  # (action_dim,)
                        adj = self.weight_adjuster(token.unsqueeze(0))  # (1, 2)
                        adjustments[b, t, :] = adj.squeeze(0)
        
        # åº”ç”¨è°ƒæ•´å¼ºåº¦
        adjustments = adjustments * self.adjustment_strength
        
        # è°ƒæ•´æƒé‡
        adjusted_weights = base_weights + adjustments
        
        # é‡æ–°å½’ä¸€åŒ–ç¡®ä¿æƒé‡å’Œä¸º1
        adjusted_weights = F.softmax(adjusted_weights / torch.clamp(self.temperature, min=0.1), dim=-1)
        
        return adjusted_weights
    
    def apply_temporal_smoothing(self, 
                               current_weights: torch.Tensor,
                               is_first_batch: bool = False) -> torch.Tensor:
        """
        åº”ç”¨æ—¶åºå¹³æ»‘
        """
        if is_first_batch or self.temporal_smoothing <= 0:
            # ç¬¬ä¸€ä¸ªbatchæˆ–ä¸å¯ç”¨å¹³æ»‘
            self.prev_weights = current_weights[:, -1:, :].detach().clone()
            return current_weights
        
        B, T, _ = current_weights.shape
        
        # ç¡®ä¿ prev_weights å½¢çŠ¶å…¼å®¹
        if self.prev_weights.shape[0] != B:
            # å¦‚æœæ‰¹æ¬¡å¤§å°ä¸åŒ¹é…ï¼Œé‡æ–°åˆå§‹åŒ–
            self.prev_weights = current_weights[:, 0:1, :].detach().clone()
            return current_weights
        
        # åˆ›å»ºå¹³æ»‘æƒé‡
        smoothed_weights = current_weights.clone()
        
        # å¯¹ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥åº”ç”¨å¹³æ»‘
        smoothed_weights[:, 0:1, :] = (
            self.temporal_smoothing * self.prev_weights + 
            (1 - self.temporal_smoothing) * current_weights[:, 0:1, :]
        )
        
        # å¯¹åºåˆ—å†…éƒ¨åº”ç”¨å¹³æ»‘
        for t in range(1, T):
            smoothed_weights[:, t:t+1, :] = (
                self.temporal_smoothing * smoothed_weights[:, t-1:t, :] + 
                (1 - self.temporal_smoothing) * current_weights[:, t:t+1, :]
            )
        
        # æ›´æ–°prev_weights
        self.prev_weights = smoothed_weights[:, -1:, :].detach().clone()
        
        return smoothed_weights
    
    def forward(self, 
                critical_labels: torch.Tensor, 
                action_tokens: Optional[torch.Tensor] = None,
                is_first_batch: bool = False) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­ï¼šç”Ÿæˆè½¯è·¯ç”±æƒé‡
        """
        B, T = critical_labels.shape
        device = critical_labels.device
        
        # 1. è·å–åŸºç¡€æƒé‡
        base_weights = self.get_base_weights(critical_labels)
        
        # 2. ç¥ç»ç½‘ç»œå¾®è°ƒï¼ˆå¯é€‰ï¼‰
        if self.enable_neural_adjustment and action_tokens is not None:
            try:
                adjusted_weights = self.apply_neural_adjustment(base_weights, action_tokens)
            except Exception as e:
                print(f"âŒ ç¥ç»ç½‘ç»œå¾®è°ƒå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€æƒé‡: {e}")
                adjusted_weights = base_weights
        else:
            adjusted_weights = base_weights
        
        # 3. æ—¶åºå¹³æ»‘
        try:
            final_weights = self.apply_temporal_smoothing(adjusted_weights, is_first_batch)
        except Exception as e:
            print(f"âŒ æ—¶åºå¹³æ»‘å¤±è´¥ï¼Œä½¿ç”¨è°ƒæ•´åæƒé‡: {e}")
            final_weights = adjusted_weights
        
        # 4. è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        critical_mask = critical_labels.bool()
        non_critical_mask = ~critical_mask
        
        statistics = {
            'critical_ratio': critical_mask.float().mean().item(),
            'avg_global_weight': final_weights[:, :, 0].mean().item(),
            'avg_depth_weight': final_weights[:, :, 1].mean().item(),
            'weight_std_global': final_weights[:, :, 0].std().item(),
            'weight_std_depth': final_weights[:, :, 1].std().item(),
            'temperature': torch.clamp(self.temperature, min=0.1).item(),
        }
        
        # åˆ†ç±»ç»Ÿè®¡
        if critical_mask.any():
            critical_weights = final_weights[critical_mask]
            statistics.update({
                'critical_avg_global': critical_weights[:, 0].mean().item(),
                'critical_avg_depth': critical_weights[:, 1].mean().item(),
            })
        
        if non_critical_mask.any():
            non_critical_weights = final_weights[non_critical_mask]
            statistics.update({
                'non_critical_avg_global': non_critical_weights[:, 0].mean().item(),
                'non_critical_avg_depth': non_critical_weights[:, 1].mean().item(),
            })
        
        # å¾®è°ƒç»Ÿè®¡
        if self.enable_neural_adjustment and action_tokens is not None:
            weight_drift = torch.norm(adjusted_weights - base_weights, dim=-1).mean()
            statistics['weight_drift'] = weight_drift.item()
        
        return {
            'routing_weights': final_weights,
            'base_weights': base_weights,
            'adjusted_weights': adjusted_weights,
            'statistics': statistics
        }


class RobustWeightAdjuster(nn.Module):
    """
    ğŸ†• æ›´å¥å£®çš„æƒé‡è°ƒæ•´å™¨ - ä¸“é—¨å¤„ç†å¼ é‡è¿ç»­æ€§é—®é¢˜
    """
    
    def __init__(self, 
                 action_dim: int = 2048, 
                 hidden_dim: int = 256,
                 adjustment_strength: float = 0.1):
        super().__init__()
        
        self.action_dim = action_dim
        self.hidden_dim = hidden_dim
        self.adjustment_strength = adjustment_strength
        
        # ç®€åŒ–çš„ç½‘ç»œç»“æ„ï¼Œå‡å°‘å¼ é‡æ“ä½œå¤æ‚æ€§
        self.net = nn.Sequential(
            nn.Linear(action_dim, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, 2),
            nn.Tanh()
        )
        
        # æƒé‡åˆå§‹åŒ–
        self._init_weights()
    
    def _init_weights(self):
        """å°åˆå§‹åŒ–ç­–ç•¥"""
        for module in self.net:
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight, gain=0.05)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
    
    def forward(self, action_tokens: torch.Tensor) -> torch.Tensor:
        """
        å¥å£®çš„å‰å‘ä¼ æ’­ï¼Œå¤„ç†å„ç§å¼ é‡è¿ç»­æ€§é—®é¢˜
        
        Args:
            action_tokens: (B, T, action_dim)
            
        Returns:
            adjustments: (B, T, 2)
        """
        B, T, action_dim = action_tokens.shape
        
        # ğŸ”§ å¤šç§æ–¹æ³•å¤„ç†å¼ é‡é‡å¡‘é—®é¢˜
        try:
            # æ–¹æ³•1ï¼šcontiguous + reshapeï¼ˆæ¨èï¼‰
            flat_tokens = action_tokens.contiguous().reshape(B * T, action_dim)
            raw_adjustments = self.net(flat_tokens)
            adjustments = raw_adjustments.reshape(B, T, 2)
            
        except Exception as e1:
            print(f"âš ï¸ æ–¹æ³•1å¤±è´¥: {e1}")
            try:
                # æ–¹æ³•2ï¼šå…‹éš† + view
                flat_tokens = action_tokens.clone().view(B * T, action_dim)
                raw_adjustments = self.net(flat_tokens)
                adjustments = raw_adjustments.view(B, T, 2)
                
            except Exception as e2:
                print(f"âš ï¸ æ–¹æ³•2å¤±è´¥: {e2}")
                try:
                    # æ–¹æ³•3ï¼šä½¿ç”¨flatten + unflatten
                    flat_tokens = torch.flatten(action_tokens, start_dim=0, end_dim=1)
                    raw_adjustments = self.net(flat_tokens)
                    adjustments = raw_adjustments.unflatten(0, (B, T))
                    
                except Exception as e3:
                    print(f"âš ï¸ æ–¹æ³•3å¤±è´¥: {e3}")
                    # æ–¹æ³•4ï¼šé€ä¸ªtokenå¤„ç†ï¼ˆä¿åº•æ–¹æ¡ˆï¼‰
                    adjustments = torch.zeros(B, T, 2, device=action_tokens.device, dtype=action_tokens.dtype)
                    for b in range(B):
                        batch_tokens = action_tokens[b]  # (T, action_dim)
                        batch_adjustments = self.net(batch_tokens)  # (T, 2)
                        adjustments[b] = batch_adjustments
        
        # åº”ç”¨è°ƒæ•´å¼ºåº¦
        adjustments = adjustments * self.adjustment_strength
        
        return adjustments


class SimpleDualTeacherModel(nn.Module):
    """
    ç®€åŒ–çš„åŒæ•™å¸ˆå¯¹é½æ¨¡å‹ - ä¿®å¤ç‰ˆ
    """
    
    def __init__(self,
                 action_dim: int = 2048,
                 dinov2_dim: int = 1024,
                 depth_dim: int = 1024,
                 router_config: Dict = None):
        super().__init__()
        
        self.action_dim = action_dim
        self.dinov2_dim = dinov2_dim
        self.depth_dim = depth_dim
        
        # åˆ›å»ºè½¯è·¯ç”±å™¨
        if router_config is None:
            router_config = {
                'action_dim': action_dim,
                'critical_global_weight': 0.25,
                'critical_depth_weight': 0.75,
                'non_critical_global_weight': 0.75,
                'non_critical_depth_weight': 0.25,
                'enable_neural_adjustment': True,
                'temporal_smoothing': 0.9,
            }
        
        self.soft_router = BinaryLabelSoftRouter(**router_config)
        
        # ç‰¹å¾æŠ•å½±å™¨
        self.dinov2_projector = nn.Sequential(
            nn.Linear(dinov2_dim, (dinov2_dim + action_dim) // 2),
            nn.LayerNorm((dinov2_dim + action_dim) // 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear((dinov2_dim + action_dim) // 2, action_dim),
            nn.LayerNorm(action_dim),
        )
        
        self.depth_projector = nn.Sequential(
            nn.Linear(depth_dim, (depth_dim + action_dim) // 2),
            nn.LayerNorm((depth_dim + action_dim) // 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear((depth_dim + action_dim) // 2, action_dim),
            nn.LayerNorm(action_dim),
        )
        
        # å¯å­¦ä¹ çš„æ¸©åº¦å‚æ•°ç”¨äºå¯¹æ¯”å­¦ä¹ 
        self.alignment_temperature = nn.Parameter(torch.tensor(0.07))
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        """åˆå§‹åŒ–ç½‘ç»œæƒé‡"""
        for module in [self.dinov2_projector, self.depth_projector]:
            for layer in module:
                if isinstance(layer, nn.Linear):
                    nn.init.xavier_uniform_(layer.weight, gain=0.5)
                    if layer.bias is not None:
                        nn.init.constant_(layer.bias, 0)
    
    def compute_alignment_loss(self,
                             action_tokens: torch.Tensor,
                             dinov2_features: torch.Tensor,
                             depth_features: torch.Tensor,
                             routing_weights: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—åŠ æƒå¯¹é½æŸå¤±
        """
        B, T, _ = action_tokens.shape
        
        # æŠ•å½±è§†è§‰ç‰¹å¾åˆ°åŠ¨ä½œç©ºé—´
        projected_dinov2 = self.dinov2_projector(dinov2_features)  # (B, action_dim)
        projected_depth = self.depth_projector(depth_features)     # (B, action_dim)
        
        # æ‰©å±•åˆ°æ—¶é—´ç»´åº¦
        projected_dinov2_expanded = projected_dinov2.unsqueeze(1).expand(-1, T, -1)
        projected_depth_expanded = projected_depth.unsqueeze(1).expand(-1, T, -1)
        
        # L2å½’ä¸€åŒ–
        action_norm = F.normalize(action_tokens, p=2, dim=-1)
        dinov2_norm = F.normalize(projected_dinov2_expanded, p=2, dim=-1)
        depth_norm = F.normalize(projected_depth_expanded, p=2, dim=-1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        global_similarity = torch.sum(action_norm * dinov2_norm, dim=-1)  # (B, T)
        depth_similarity = torch.sum(action_norm * depth_norm, dim=-1)    # (B, T)
        
        # æ¸©åº¦ç¼©æ”¾
        temp = torch.clamp(self.alignment_temperature, min=0.01)
        
        # è½¬æ¢ä¸ºæŸå¤±ï¼ˆæœ€å¤§åŒ–ç›¸ä¼¼åº¦ = æœ€å°åŒ–è´Ÿç›¸ä¼¼åº¦ï¼‰
        global_loss = 1.0 - global_similarity  # (B, T)
        depth_loss = 1.0 - depth_similarity    # (B, T)
        
        # åº”ç”¨è·¯ç”±æƒé‡
        weighted_global_loss = routing_weights[:, :, 0] * global_loss  # (B, T)
        weighted_depth_loss = routing_weights[:, :, 1] * depth_loss    # (B, T)
        
        # æ€»æŸå¤±
        total_alignment_loss = (weighted_global_loss + weighted_depth_loss).mean()
        
        # ğŸ”§ ç®€åŒ–å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼Œé¿å…å¤æ‚çš„å¼ é‡æ“ä½œ
        contrastive_loss = torch.tensor(0.0, device=action_tokens.device, dtype=action_tokens.dtype)
        
        # ç»„åˆæŸå¤±
        combined_loss = total_alignment_loss + 0.1 * contrastive_loss
        
        return {
            'total_loss': combined_loss,
            'alignment_loss': total_alignment_loss,
            'contrastive_loss': contrastive_loss,
            'global_loss_raw': global_loss.mean(),
            'depth_loss_raw': depth_loss.mean(),
            'weighted_global_loss': weighted_global_loss.mean(),
            'weighted_depth_loss': weighted_depth_loss.mean(),
            'global_similarity_avg': global_similarity.mean(),
            'depth_similarity_avg': depth_similarity.mean(),
            'alignment_temperature': temp.item(),
        }
    
    def forward(self,
                action_tokens: torch.Tensor,
                dinov2_features: torch.Tensor,
                depth_features: torch.Tensor,
                critical_labels: torch.Tensor,
                is_first_batch: bool = False) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        """
        B, T, action_dim = action_tokens.shape
        
        # ç¡®ä¿critical_labelså½¢çŠ¶æ­£ç¡®
        if critical_labels.shape != (B, T):
            if critical_labels.numel() == B * T:
                critical_labels = critical_labels.reshape(B, T)
            else:
                raise ValueError(f"æ— æ³•ä¿®æ­£critical_labelså½¢çŠ¶: {critical_labels.shape}")
        
        # 1. ç”Ÿæˆè·¯ç”±æƒé‡
        routing_results = self.soft_router(
            critical_labels, 
            action_tokens, 
            is_first_batch
        )
        
        routing_weights = routing_results['routing_weights']
        
        # 2. è®¡ç®—å¯¹é½æŸå¤±
        alignment_results = self.compute_alignment_loss(
            action_tokens,
            dinov2_features,
            depth_features,
            routing_weights
        )
        
        # 3. åˆå¹¶ç»“æœ
        results = {
            **alignment_results,
            'routing_weights': routing_weights,
            'router_statistics': routing_results['statistics'],
            'base_weights': routing_results['base_weights'],
        }
        
        return results


# æµ‹è¯•ä¿®å¤åçš„ä»£ç 
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•ä¿®å¤view/reshapeé”™è¯¯çš„è½¯è·¯ç”±æ¡†æ¶")
    
    # åˆ›å»ºå„ç§å½¢çŠ¶çš„æµ‹è¯•æ•°æ®
    test_cases = [
        (2, 64, 2048),   # åŸå§‹é”™è¯¯æ¡ˆä¾‹
        (16, 64, 2048),  # ç¬¬ä¸€ä¸ªé”™è¯¯æ¡ˆä¾‹
        (4, 128, 2048),  # å…¶ä»–æƒ…å†µ
    ]
    
    for B, T, action_dim in test_cases:
        print(f"\nğŸ“Š æµ‹è¯•æ¡ˆä¾‹: B={B}, T={T}, action_dim={action_dim}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        action_tokens = torch.randn(B, T, action_dim)
        critical_labels = torch.randint(0, 2, (B, T))
        
        # æµ‹è¯•è½¯è·¯ç”±å™¨
        try:
            router_config = {
                'action_dim': action_dim,
                'critical_global_weight': 0.25,
                'critical_depth_weight': 0.75,
                'non_critical_global_weight': 0.75,
                'non_critical_depth_weight': 0.25,
                'enable_neural_adjustment': True,
                'temporal_smoothing': 0.9,
            }
            
            soft_router = BinaryLabelSoftRouter(**router_config)
            routing_results = soft_router(critical_labels, action_tokens, is_first_batch=True)
            
            print(f"âœ… è½¯è·¯ç”±å™¨æµ‹è¯•æˆåŠŸ!")
            print(f"   - è·¯ç”±æƒé‡å½¢çŠ¶: {routing_results['routing_weights'].shape}")
            
        except Exception as e:
            print(f"âŒ è½¯è·¯ç”±å™¨æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print("\nğŸŠ view/reshapeé”™è¯¯ä¿®å¤æµ‹è¯•å®Œæˆ!")