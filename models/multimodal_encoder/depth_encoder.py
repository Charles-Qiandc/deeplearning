import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import AutoImageProcessor, AutoModelForDepthEstimation
import numpy as np


class DepthAnythingV2Encoder(nn.Module):
    """
    DepthAnythingV2ç¼–ç å™¨ï¼Œæä¾›æ·±åº¦æ„ŸçŸ¥çš„å‡ ä½•ç‰¹å¾
    ğŸ†• ç¡®ä¿è¿”å›åŒ…å«CLS tokençš„ç‰¹å¾ç”¨äºåŒæ•™å¸ˆå¯¹é½
    """
    
    def __init__(self, model_size="vits", feature_dim=1024, device=None):
        """
        åˆå§‹åŒ–DepthAnythingV2ç¼–ç å™¨
        
        Args:
            model_size: æ¨¡å‹å¤§å° ("vits", "vitb", "vitl")
            feature_dim: è¾“å‡ºç‰¹å¾ç»´åº¦ï¼Œéœ€è¦ä¸DINOv2å¯¹é½ (1024)
            device: è®¡ç®—è®¾å¤‡
        """
        super().__init__()
        
        self.model_size = model_size
        self.feature_dim = feature_dim
        self.device = device if device else torch.device('cpu')
        
        # æ¨¡å‹åç§°æ˜ å°„
        model_mapping = {
            "vits": "depth-anything/Depth-Anything-V2-Small-hf",
            "vitb": "depth-anything/Depth-Anything-V2-Base-hf", 
            "vitl": "depth-anything/Depth-Anything-V2-Large-hf"
        }
        
        if model_size not in model_mapping:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹å¤§å°: {model_size}")
        
        self.model_name = model_mapping[model_size]
        self.is_loaded = False
        
        # å»¶è¿ŸåŠ è½½ä»¥èŠ‚çœåˆå§‹åŒ–æ—¶é—´
        self.image_processor = None
        self.depth_model = None
        self.projection_head = None
        
    def load_model(self):
        """å»¶è¿ŸåŠ è½½æ¨¡å‹æƒé‡"""
        if self.is_loaded:
            return
            
        print(f"ğŸ”§ åŠ è½½DepthAnythingV2æ¨¡å‹: {self.model_name}")
        
        # åŠ è½½é¢„å¤„ç†å™¨å’Œæ¨¡å‹
        self.image_processor = AutoImageProcessor.from_pretrained(self.model_name)
        self.depth_model = AutoModelForDepthEstimation.from_pretrained(self.model_name)
        
        # å†»ç»“æ·±åº¦æ¨¡å‹æƒé‡ï¼ˆåªç”¨äºç‰¹å¾æå–ï¼‰
        self.depth_model.eval()
        for param in self.depth_model.parameters():
            param.requires_grad = False
            
        # è·å–æ·±åº¦æ¨¡å‹çš„éšè—ç»´åº¦
        if hasattr(self.depth_model.config, 'hidden_size'):
            depth_hidden_size = self.depth_model.config.hidden_size
        else:
            # æ ¹æ®æ¨¡å‹å¤§å°ä¼°ç®—
            size_to_dim = {"vits": 384, "vitb": 768, "vitl": 1024}
            depth_hidden_size = size_to_dim.get(self.model_size, 768)
            
        print(f"   æ·±åº¦æ¨¡å‹éšè—ç»´åº¦: {depth_hidden_size}")
        print(f"   ç›®æ ‡è¾“å‡ºç»´åº¦: {self.feature_dim}")
        
        # åˆ›å»ºæŠ•å½±å¤´ï¼Œå°†æ·±åº¦ç‰¹å¾æ˜ å°„åˆ°ç›®æ ‡ç»´åº¦
        self.projection_head = nn.Sequential(
            nn.Linear(depth_hidden_size, depth_hidden_size * 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(depth_hidden_size * 2, self.feature_dim),
            nn.LayerNorm(self.feature_dim)
        )
        
        # åˆå§‹åŒ–æŠ•å½±å¤´æƒé‡
        for module in self.projection_head:
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight, gain=0.5)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
                    
        # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        self.depth_model = self.depth_model.to(self.device)
        self.projection_head = self.projection_head.to(self.device)
        
        self.is_loaded = True
        print(f"âœ… DepthAnythingV2ç¼–ç å™¨åŠ è½½å®Œæˆ")
        
    def extract_intermediate_features(self, images):
        """
        ğŸ”„ ç¡®ä¿æå–åŒ…å«CLS tokençš„ä¸­é—´ç‰¹å¾
        """
        # è·å–ç¼–ç å™¨çš„ä¸­é—´æ¿€æ´»
        outputs = self.depth_model.backbone(
            images, 
            output_hidden_states=True,
            return_dict=True
        )
        
        # ä½¿ç”¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€ä½œä¸ºç‰¹å¾
        if hasattr(outputs, 'last_hidden_state'):
            features = outputs.last_hidden_state
        elif hasattr(outputs, 'hidden_states'):
            features = outputs.hidden_states[-1]
        else:
            raise ValueError("æ— æ³•ä»æ·±åº¦æ¨¡å‹æå–ç‰¹å¾")
        
        # éªŒè¯ç‰¹å¾æ ¼å¼
        # features shapeåº”è¯¥æ˜¯ (B, 1370, hidden_dim)
        # å…¶ä¸­ç¬¬0ä¸ªtokenæ˜¯CLS tokenï¼Œç¬¬1-1369ä¸ªæ˜¯patch tokens
        if features.shape[1] != 1370:
            print(f"âš ï¸ è­¦å‘Š: æ·±åº¦ç‰¹å¾æ•°é‡ä¸æ˜¯1370ï¼Œè€Œæ˜¯{features.shape[1]}")
            print(f"è¿™å¯èƒ½æ„å‘³ç€CLS tokençš„ä½ç½®ä¸åŒæˆ–è€…patchæ•°é‡ä¸åŒ")
        
        return features

    @torch.no_grad()
    def forward(self, images):
        """
        ğŸ”„ å‰å‘ä¼ æ’­ï¼Œç¡®ä¿è¿”å›æ­£ç¡®æ ¼å¼çš„æ·±åº¦ç‰¹å¾
        
        Args:
            images: (B, 3, H, W) RGBå›¾åƒå¼ é‡
            
        Returns:
            depth_features: (B, 1370, feature_dim) æ·±åº¦ç‰¹å¾tokens
                           å…¶ä¸­ç¬¬0ä¸ªtokenæ˜¯CLS tokenï¼ŒåŒ…å«å…¨å±€æ·±åº¦ä¿¡æ¯
            depth_map: (B, 1, H, W) é¢„æµ‹çš„æ·±åº¦å›¾ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        """
        if not self.is_loaded:
            self.load_model()
            
        B, C, H, W = images.shape
        
        # ç¡®ä¿è¾“å…¥æ˜¯RGBæ ¼å¼ä¸”å°ºå¯¸æ­£ç¡®
        assert C == 3, f"æœŸæœ›3é€šé“RGBå›¾åƒï¼Œå¾—åˆ°{C}é€šé“"
        
        if H != 518 or W != 518:
            images = F.interpolate(
                images, 
                size=(518, 518), 
                mode='bilinear', 
                align_corners=False
            )
        
        try:
            # æå–ä¸­é—´ç‰¹å¾ï¼ˆåŒ…å«CLS tokenï¼‰
            intermediate_features = self.extract_intermediate_features(images)
            
            # intermediate_features shape: (B, 1370, hidden_dim)
            # ç¬¬0ä¸ªtokenæ˜¯CLS tokenï¼Œç¬¬1-1369ä¸ªæ˜¯patch tokens
            B, N, D = intermediate_features.shape
            
            print(f"ğŸ” æ·±åº¦ç‰¹å¾shape: {intermediate_features.shape}")
            print(f"   - CLS token: features[:, 0, :] shape = ({B}, {D})")
            print(f"   - Patch tokens: features[:, 1:, :] shape = ({B}, {N-1}, {D})")
            
            # é€šè¿‡æŠ•å½±å¤´æ˜ å°„åˆ°ç›®æ ‡ç»´åº¦
            depth_features = self.projection_head(
                intermediate_features.reshape(B * N, D)
            ).reshape(B, N, self.feature_dim)
            
            # éªŒè¯CLS tokenå­˜åœ¨
            cls_token = depth_features[:, 0, :]  # (B, feature_dim)
            patch_tokens = depth_features[:, 1:, :]  # (B, 1369, feature_dim)
            
            print(f"âœ… æŠ•å½±åæ·±åº¦ç‰¹å¾:")
            print(f"   - CLS token shape: {cls_token.shape}")
            print(f"   - Patch tokens shape: {patch_tokens.shape}")
            
        except Exception as e:
            print(f"âš ï¸ æ— æ³•æå–ä¸­é—´ç‰¹å¾ï¼Œé™çº§ä½¿ç”¨æ·±åº¦å›¾: {e}")
            
            # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨æ·±åº¦é¢„æµ‹ä½œä¸ºç‰¹å¾æº
            outputs = self.depth_model(images)
            predicted_depth = outputs.predicted_depth  # (B, H', W')
            
            # å°†æ·±åº¦å›¾è½¬æ¢ä¸ºpatch tokensï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            patch_size = 14
            num_patches = (518 // patch_size) ** 2  # 37 * 37 = 1369
            
            # åˆ›å»ºå‡çš„CLS tokenå’Œpatch tokens
            fake_cls = torch.randn(B, 1, self.feature_dim, device=images.device, dtype=images.dtype)
            fake_patches = torch.randn(B, num_patches, self.feature_dim, device=images.device, dtype=images.dtype)
            
            depth_features = torch.cat([fake_cls, fake_patches], dim=1)  # (B, 1370, feature_dim)
            
            print(f"âš ï¸ ä½¿ç”¨é™çº§æ–¹æ¡ˆï¼Œç”Ÿæˆçš„æ·±åº¦ç‰¹å¾shape: {depth_features.shape}")
        
        # ç”Ÿæˆæ·±åº¦å›¾ç”¨äºå¯è§†åŒ–
        with torch.no_grad():
            outputs = self.depth_model(images)
            depth_map = outputs.predicted_depth.unsqueeze(1)  # (B, 1, H, W)
            depth_map = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min() + 1e-8)
        
        return depth_features, depth_map
    
    def get_cls_token(self, depth_features):
        """
        ğŸ†• ä»æ·±åº¦ç‰¹å¾ä¸­æå–CLS token
        
        Args:
            depth_features: (B, 1370, feature_dim) æ·±åº¦ç‰¹å¾
            
        Returns:
            cls_token: (B, feature_dim) CLS token
        """
        if depth_features.shape[1] >= 1:
            return depth_features[:, 0, :]  # ç¬¬0ä¸ªtokenæ˜¯CLS
        else:
            raise ValueError("æ·±åº¦ç‰¹å¾ä¸­æ²¡æœ‰è¶³å¤Ÿçš„tokens")
    
    def get_patch_tokens(self, depth_features):
        """
        ğŸ†• ä»æ·±åº¦ç‰¹å¾ä¸­æå–patch tokens
        
        Args:
            depth_features: (B, 1370, feature_dim) æ·±åº¦ç‰¹å¾
            
        Returns:
            patch_tokens: (B, 1369, feature_dim) patch tokens
        """
        if depth_features.shape[1] >= 1370:
            return depth_features[:, 1:, :]  # ç¬¬1-1369ä¸ªtokenæ˜¯patches
        else:
            raise ValueError("æ·±åº¦ç‰¹å¾ä¸­æ²¡æœ‰è¶³å¤Ÿçš„tokens")

    @property
    def dtype(self):
        """è¿”å›æ¨¡å‹æ•°æ®ç±»å‹"""
        if self.is_loaded and self.depth_model is not None:
            return next(self.depth_model.parameters()).dtype
        return torch.float32
    
    @property
    def device(self):
        """è¿”å›æ¨¡å‹è®¾å¤‡"""
        if self.is_loaded and self.depth_model is not None:
            return next(self.depth_model.parameters()).device
        return torch.device('cpu')
    
    def print_model_info(self):
        """æ‰“å°æ¨¡å‹ä¿¡æ¯ç”¨äºè°ƒè¯•"""
        if not self.is_loaded:
            print("âŒ æ¨¡å‹æœªåŠ è½½")
            return
            
        print("ğŸ” DepthAnythingV2ç¼–ç å™¨ä¿¡æ¯:")
        print(f"   - æ¨¡å‹åç§°: {self.model_name}")
        print(f"   - æ¨¡å‹å¤§å°: {self.model_size}")
        print(f"   - è¾“å‡ºç‰¹å¾ç»´åº¦: {self.feature_dim}")
        print(f"   - è®¾å¤‡: {self.device}")
        print(f"   - æ•°æ®ç±»å‹: {self.dtype}")
        print(f"   - æœŸæœ›è¾“å‡ºæ ¼å¼: (B, 1370, {self.feature_dim})")
        print(f"     - CLS token: [:, 0, :] -> (B, {self.feature_dim})")
        print(f"     - Patch tokens: [:, 1:, :] -> (B, 1369, {self.feature_dim})")
        
        # è®¡ç®—å‚æ•°é‡
        if self.depth_model is not None:
            depth_params = sum(p.numel() for p in self.depth_model.parameters())
            print(f"   - æ·±åº¦æ¨¡å‹å‚æ•°é‡: {depth_params/1e6:.2f}M")
        if self.projection_head is not None:
            proj_params = sum(p.numel() for p in self.projection_head.parameters())
            print(f"   - æŠ•å½±å¤´å‚æ•°é‡: {proj_params/1e6:.2f}M")


def create_depth_encoder(model_size="vits", feature_dim=1024, device=None):
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºDepthAnythingV2ç¼–ç å™¨
    
    Args:
        model_size: æ¨¡å‹å¤§å° ("vits", "vitb", "vitl")
        feature_dim: è¾“å‡ºç‰¹å¾ç»´åº¦
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        DepthAnythingV2Encoderå®ä¾‹
    """
    encoder = DepthAnythingV2Encoder(
        model_size=model_size,
        feature_dim=feature_dim,
        device=device
    )
    return encoder


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•DepthAnythingV2ç¼–ç å™¨")
    
    # åˆ›å»ºç¼–ç å™¨
    encoder = create_depth_encoder(model_size="vits")
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    encoder.print_model_info()
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    print("\nğŸ”¬ æµ‹è¯•å‰å‘ä¼ æ’­:")
    test_input = torch.randn(2, 3, 518, 518)
    depth_features, depth_map = encoder(test_input)
    
    print(f"è¾“å…¥å½¢çŠ¶: {test_input.shape}")
    print(f"æ·±åº¦ç‰¹å¾å½¢çŠ¶: {depth_features.shape}")
    print(f"æ·±åº¦å›¾å½¢çŠ¶: {depth_map.shape}")
    
    # æµ‹è¯•CLS tokenæå–
    cls_token = encoder.get_cls_token(depth_features)
    patch_tokens = encoder.get_patch_tokens(depth_features)
    print(f"CLS tokenå½¢çŠ¶: {cls_token.shape}")
    print(f"Patch tokenså½¢çŠ¶: {patch_tokens.shape}")
    
    # éªŒè¯ç‰¹å¾æ ¼å¼
    assert depth_features.shape == (2, 1370, 1024), f"æœŸæœ›å½¢çŠ¶ (2, 1370, 1024)ï¼Œå®é™… {depth_features.shape}"
    assert cls_token.shape == (2, 1024), f"æœŸæœ›CLS tokenå½¢çŠ¶ (2, 1024)ï¼Œå®é™… {cls_token.shape}"
    assert patch_tokens.shape == (2, 1369, 1024), f"æœŸæœ›patch tokenså½¢çŠ¶ (2, 1369, 1024)ï¼Œå®é™… {patch_tokens.shape}"
    
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("\nğŸ¯ å…³é”®ç‚¹:")
    print(f"   - DepthAnythingV2è¿”å› (B, 1370, 1024) ç‰¹å¾")
    print(f"   - CLS tokenä½ç½®: [:, 0, :] åŒ…å«å…¨å±€æ·±åº¦è¯­ä¹‰")
    print(f"   - Patch tokensä½ç½®: [:, 1:, :] åŒ…å«å±€éƒ¨æ·±åº¦ä¿¡æ¯")
    print(f"   - ä¸DINOv2ç‰¹å¾ç»´åº¦å¯¹é½: 1024ç»´")