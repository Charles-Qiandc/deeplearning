"""
SigLIP å…¨å±€ç‰¹å¾æå–å™¨
ç”¨äºREPAå¯¹é½çš„CLS tokenæå–
"""

import torch
import torch.nn as nn
from models.multimodal_encoder.siglip_encoder import SiglipVisionTower


class SiglipGlobalFeatureExtractor(nn.Module):
    """
    SigLIPå…¨å±€ç‰¹å¾æå–å™¨
    ä»SigLIPçš„æœ€åä¸€å±‚æå–å…¨å±€è¡¨ç¤ºç”¨äºREPAå¯¹é½
    
    æ³¨æ„ï¼šSigLIPæ²¡æœ‰æ˜¾å¼çš„CLS tokenï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸¤ç§ç­–ç•¥ï¼š
    1. å…¨å±€å¹³å‡æ± åŒ–æ‰€æœ‰patch tokens
    2. ä½¿ç”¨ç¬¬ä¸€ä¸ªtokenä½œä¸ºç±»CLSè¡¨ç¤º
    """
    
    def __init__(
        self, 
        vision_tower_name: str = "google/siglip-so400m-patch14-384",
        pooling_strategy: str = "mean",  # "mean" | "first_token" | "max"
        feature_dim: int = 1152,
        args=None
    ):
        """
        Args:
            vision_tower_name: SigLIPæ¨¡å‹åç§°
            pooling_strategy: æ± åŒ–ç­–ç•¥
                - "mean": å¹³å‡æ± åŒ–æ‰€æœ‰patch tokens
                - "first_token": ä½¿ç”¨ç¬¬ä¸€ä¸ªtoken
                - "max": æœ€å¤§æ± åŒ–
            feature_dim: è¾“å‡ºç‰¹å¾ç»´åº¦ï¼ˆSigLIP-SO400Mä¸º1152ï¼‰
            args: é¢å¤–å‚æ•°
        """
        super().__init__()
        
        self.vision_tower_name = vision_tower_name
        self.pooling_strategy = pooling_strategy
        self.feature_dim = feature_dim
        self.is_loaded = False
        
        # å¤ç”¨ç°æœ‰çš„SigLIPç¼–ç å™¨
        self.siglip_encoder = SiglipVisionTower(
            vision_tower=vision_tower_name,
            args=args,
            delay_load=False
        )
        
        self.is_loaded = True
        
        print(f"âœ… SigLIPå…¨å±€ç‰¹å¾æå–å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   - æ¨¡å‹: {vision_tower_name}")
        print(f"   - æ± åŒ–ç­–ç•¥: {pooling_strategy}")
        print(f"   - ç‰¹å¾ç»´åº¦: {feature_dim}")
    
    def _pool_features(self, patch_tokens: torch.Tensor) -> torch.Tensor:
        """
        å¯¹patch tokensè¿›è¡Œæ± åŒ–å¾—åˆ°å…¨å±€ç‰¹å¾
        
        Args:
            patch_tokens: (B, N, D) patchçº§åˆ«çš„ç‰¹å¾
            
        Returns:
            global_features: (B, 1, D) å…¨å±€ç‰¹å¾
        """
        if self.pooling_strategy == "mean":
            # å¹³å‡æ± åŒ–
            global_features = patch_tokens.mean(dim=1, keepdim=True)
        
        elif self.pooling_strategy == "first_token":
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªtoken
            global_features = patch_tokens[:, :1, :]
        
        elif self.pooling_strategy == "max":
            # æœ€å¤§æ± åŒ–
            global_features = patch_tokens.max(dim=1, keepdim=True)[0]
        
        else:
            raise ValueError(f"æœªçŸ¥çš„æ± åŒ–ç­–ç•¥: {self.pooling_strategy}")
        
        return global_features
    
    @torch.no_grad()
    def forward(self, images: torch.Tensor) -> torch.Tensor:
        """
        æå–å…¨å±€ç‰¹å¾ï¼ˆç±»CLS tokenï¼‰
        
        Args:
            images: (B, C, H, W) è¾“å…¥å›¾åƒ
            
        Returns:
            global_features: (B, 1, D) å…¨å±€ç‰¹å¾ï¼Œç»´åº¦ä¸DINOv2 CLS tokenä¸€è‡´
        """
        if not self.is_loaded:
            raise RuntimeError("SigLIP encoderæœªåŠ è½½")
        
        # è·å–patch-levelç‰¹å¾
        patch_tokens = self.siglip_encoder(images)  # (B, 729, 1152)
        
        # æ± åŒ–å¾—åˆ°å…¨å±€ç‰¹å¾
        global_features = self._pool_features(patch_tokens)  # (B, 1, 1152)
        
        return global_features
    
    @property
    def dtype(self):
        return self.siglip_encoder.dtype
    
    @property
    def device(self):
        return self.siglip_encoder.device
    
    @property
    def hidden_size(self):
        return self.feature_dim
    
    def print_model_info(self):
        """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
        print("ğŸ” SigLIPå…¨å±€ç‰¹å¾æå–å™¨ä¿¡æ¯:")
        print(f"   - æ¨¡å‹åç§°: {self.vision_tower_name}")
        print(f"   - æ± åŒ–ç­–ç•¥: {self.pooling_strategy}")
        print(f"   - è¾“å‡ºç»´åº¦: {self.feature_dim}")
        print(f"   - è¾“å‡ºæ ¼å¼: (B, 1, {self.feature_dim}) - ç±»CLS token")
        print(f"   - è®¾å¤‡: {self.device}")
        print(f"   - æ•°æ®ç±»å‹: {self.dtype}")


def create_siglip_global_encoder(
    model_name: str = "google/siglip-so400m-patch14-384",
    pooling_strategy: str = "mean",
    feature_dim: int = 1152,
    device=None
):
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºSigLIPå…¨å±€ç‰¹å¾æå–å™¨
    
    Args:
        model_name: SigLIPæ¨¡å‹åç§°
        pooling_strategy: æ± åŒ–ç­–ç•¥
        feature_dim: ç‰¹å¾ç»´åº¦
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        SiglipGlobalFeatureExtractorå®ä¾‹
    """
    print(f"ğŸ”§ åˆ›å»ºSigLIPå…¨å±€ç‰¹å¾æå–å™¨")
    print(f"   - æ¨¡å‹: {model_name}")
    print(f"   - æ± åŒ–ç­–ç•¥: {pooling_strategy}")
    
    encoder = SiglipGlobalFeatureExtractor(
        vision_tower_name=model_name,
        pooling_strategy=pooling_strategy,
        feature_dim=feature_dim
    )
    
    if device is not None:
        encoder.to(device)
    
    return encoder


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•SigLIPå…¨å±€ç‰¹å¾æå–å™¨")
    
    # åˆ›å»ºç¼–ç å™¨
    encoder = create_siglip_global_encoder()
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    print("\nğŸ”¬ æµ‹è¯•å‰å‘ä¼ æ’­:")
    test_input = torch.randn(2, 3, 384, 384)
    
    global_features = encoder(test_input)
    
    print(f"è¾“å…¥å½¢çŠ¶: {test_input.shape}")
    print(f"å…¨å±€ç‰¹å¾å½¢çŠ¶: {global_features.shape}")
    print(f"æœŸæœ›å½¢çŠ¶: (2, 1, 1152)")
    
    assert global_features.shape == (2, 1, 1152), "è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…ï¼"
    
    print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")