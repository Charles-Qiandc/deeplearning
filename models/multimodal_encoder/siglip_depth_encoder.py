"""
SigLIP æ·±åº¦ç‰¹å¾æå–å™¨
ä½œä¸ºæ·±åº¦æ•™å¸ˆçš„æ›¿ä»£æ–¹æ¡ˆ
"""

import torch
import torch.nn as nn
from models.multimodal_encoder.siglip_encoder import SiglipVisionTower


class SiglipDepthFeatureExtractor(nn.Module):
    """
    SigLIPæ·±åº¦ç‰¹å¾æå–å™¨
    ä½¿ç”¨SigLIPçš„patch tokensä½œä¸ºæ·±åº¦æ„ŸçŸ¥ç‰¹å¾
    
    ä¸DepthAnythingV2ä¸åŒï¼ŒSigLIPæä¾›çš„æ˜¯RGBç‰¹å¾è€ŒéçœŸå®æ·±åº¦ä¿¡æ¯ï¼Œ
    ä½†åŒæ ·å¯ä»¥ç”¨äºå‡ ä½•å¯¹é½
    """
    
    def __init__(
        self, 
        vision_tower_name: str = "google/siglip-so400m-patch14-384",
        feature_dim: int = 1152,
        output_format: str = "patch_tokens",  # "patch_tokens" | "cls_patch"
        args=None
    ):
        """
        Args:
            vision_tower_name: SigLIPæ¨¡å‹åç§°
            feature_dim: è¾“å‡ºç‰¹å¾ç»´åº¦ï¼ˆSigLIP-SO400Mä¸º1152ï¼‰
            output_format: è¾“å‡ºæ ¼å¼
                - "patch_tokens": åªè¿”å›patch tokens (729ä¸ª)
                - "cls_patch": è¿”å›ç±»CLS + patch tokens (730ä¸ª)
            args: é¢å¤–å‚æ•°
        """
        super().__init__()
        
        self.vision_tower_name = vision_tower_name
        self.feature_dim = feature_dim
        self.output_format = output_format
        self.is_loaded = False
        
        # å¤ç”¨ç°æœ‰çš„SigLIPç¼–ç å™¨
        self.siglip_encoder = SiglipVisionTower(
            vision_tower=vision_tower_name,
            args=args,
            delay_load=False
        )
        
        self.is_loaded = True
        
        print(f"âœ… SigLIPæ·±åº¦ç‰¹å¾æå–å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   - æ¨¡å‹: {vision_tower_name}")
        print(f"   - è¾“å‡ºæ ¼å¼: {output_format}")
        print(f"   - ç‰¹å¾ç»´åº¦: {feature_dim}")
    
    @torch.no_grad()
    def forward(self, images: torch.Tensor) -> tuple:
        """
        æå–æ·±åº¦æ„ŸçŸ¥ç‰¹å¾ï¼ˆå®é™…æ˜¯RGBçš„patchç‰¹å¾ï¼‰
        
        Args:
            images: (B, C, H, W) è¾“å…¥å›¾åƒ
            
        Returns:
            depth_features: (B, N, D) æ·±åº¦ç‰¹å¾
                - N = 729 (patch_tokens) æˆ– 730 (cls_patch)
                - D = 1152
            depth_map: (B, 1, H, W) ä¼ªæ·±åº¦å›¾ï¼ˆå®é™…æ˜¯ç‰¹å¾å¯è§†åŒ–ï¼‰
        """
        if not self.is_loaded:
            raise RuntimeError("SigLIP encoderæœªåŠ è½½")
        
        B, C, H, W = images.shape
        
        # è·å–patch-levelç‰¹å¾
        patch_tokens = self.siglip_encoder(images)  # (B, 729, 1152)
        
        # æ ¹æ®è¾“å‡ºæ ¼å¼å¤„ç†
        if self.output_format == "patch_tokens":
            depth_features = patch_tokens  # (B, 729, 1152)
        elif self.output_format == "cls_patch":
            # æ·»åŠ ä¸€ä¸ªä¼ªCLS tokenï¼ˆå¹³å‡æ± åŒ–ï¼‰
            cls_token = patch_tokens.mean(dim=1, keepdim=True)  # (B, 1, 1152)
            depth_features = torch.cat([cls_token, patch_tokens], dim=1)  # (B, 730, 1152)
        else:
            raise ValueError(f"æœªçŸ¥çš„è¾“å‡ºæ ¼å¼: {self.output_format}")
        
        # ç”Ÿæˆä¼ªæ·±åº¦å›¾ï¼ˆç”¨äºå¯è§†åŒ–ï¼Œå®é™…ä¸æ˜¯çœŸå®æ·±åº¦ï¼‰
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªé€šé“çš„ç‰¹å¾é‡å¡‘ä¸ºç©ºé—´å›¾
        spatial_dim = int(patch_tokens.shape[1] ** 0.5)  # 27 for 729 patches
        if spatial_dim * spatial_dim == patch_tokens.shape[1]:
            # å¯ä»¥é‡å¡‘ä¸ºç©ºé—´å›¾
            feature_map = patch_tokens[:, :, 0].reshape(B, 1, spatial_dim, spatial_dim)
            # ä¸Šé‡‡æ ·åˆ°åŸå§‹å°ºå¯¸
            depth_map = torch.nn.functional.interpolate(
                feature_map, 
                size=(H, W), 
                mode='bilinear', 
                align_corners=False
            )
            # å½’ä¸€åŒ–åˆ°[0, 1]
            depth_map = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min() + 1e-8)
        else:
            # æ— æ³•é‡å¡‘ï¼Œè¿”å›é›¶å›¾
            depth_map = torch.zeros(B, 1, H, W, device=images.device, dtype=images.dtype)
        
        return depth_features, depth_map
    
    def get_cls_token(self, depth_features: torch.Tensor) -> torch.Tensor:
        """
        ä»æ·±åº¦ç‰¹å¾ä¸­æå–CLS token
        
        Args:
            depth_features: (B, N, D) æ·±åº¦ç‰¹å¾
            
        Returns:
            cls_token: (B, D) CLS token
        """
        if self.output_format == "cls_patch":
            # ç¬¬ä¸€ä¸ªtokenæ˜¯CLS
            return depth_features[:, 0, :]
        else:
            # æ²¡æœ‰æ˜¾å¼CLSï¼Œä½¿ç”¨å¹³å‡æ± åŒ–
            return depth_features.mean(dim=1)
    
    def get_patch_tokens(self, depth_features: torch.Tensor) -> torch.Tensor:
        """
        ä»æ·±åº¦ç‰¹å¾ä¸­æå–patch tokens
        
        Args:
            depth_features: (B, N, D) æ·±åº¦ç‰¹å¾
            
        Returns:
            patch_tokens: (B, N_patches, D) patch tokens
        """
        if self.output_format == "cls_patch":
            # è·³è¿‡ç¬¬ä¸€ä¸ªCLS token
            return depth_features[:, 1:, :]
        else:
            # å…¨éƒ¨éƒ½æ˜¯patch tokens
            return depth_features
    
    @property
    def dtype(self):
        return self.siglip_encoder.dtype
    
    @property
    def device(self):
        return self.siglip_encoder.device
    
    @property
    def hidden_size(self):
        return self.feature_dim
    
    @property
    def num_patches(self):
        """è¿”å›patchæ•°é‡"""
        if self.output_format == "cls_patch":
            return 730  # CLS + 729 patches
        else:
            return 729  # åªæœ‰patches
    
    def print_model_info(self):
        """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
        print("ğŸ” SigLIPæ·±åº¦ç‰¹å¾æå–å™¨ä¿¡æ¯:")
        print(f"   - æ¨¡å‹åç§°: {self.vision_tower_name}")
        print(f"   - è¾“å‡ºæ ¼å¼: {self.output_format}")
        print(f"   - ç‰¹å¾ç»´åº¦: {self.feature_dim}")
        print(f"   - Tokenæ•°é‡: {self.num_patches}")
        if self.output_format == "cls_patch":
            print(f"   - è¾“å‡ºæ ¼å¼: (B, 730, {self.feature_dim}) - CLS + patches")
        else:
            print(f"   - è¾“å‡ºæ ¼å¼: (B, 729, {self.feature_dim}) - patches only")
        print(f"   - è®¾å¤‡: {self.device}")
        print(f"   - æ•°æ®ç±»å‹: {self.dtype}")
        print(f"   âš ï¸  æ³¨æ„: è¿™æ˜¯RGBç‰¹å¾ï¼Œä¸æ˜¯çœŸå®æ·±åº¦ä¿¡æ¯")


def create_siglip_depth_encoder(
    model_name: str = "google/siglip-so400m-patch14-384",
    feature_dim: int = 1152,
    output_format: str = "patch_tokens",
    device=None
):
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºSigLIPæ·±åº¦ç‰¹å¾æå–å™¨
    
    Args:
        model_name: SigLIPæ¨¡å‹åç§°
        feature_dim: ç‰¹å¾ç»´åº¦
        output_format: è¾“å‡ºæ ¼å¼
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        SiglipDepthFeatureExtractorå®ä¾‹
    """
    print(f"ğŸ”§ åˆ›å»ºSigLIPæ·±åº¦ç‰¹å¾æå–å™¨")
    print(f"   - æ¨¡å‹: {model_name}")
    print(f"   - è¾“å‡ºæ ¼å¼: {output_format}")
    
    encoder = SiglipDepthFeatureExtractor(
        vision_tower_name=model_name,
        feature_dim=feature_dim,
        output_format=output_format
    )
    
    if device is not None:
        encoder.to(device)
    
    return encoder


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•SigLIPæ·±åº¦ç‰¹å¾æå–å™¨")
    
    # åˆ›å»ºç¼–ç å™¨
    encoder = create_siglip_depth_encoder()
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    print("\nğŸ”¬ æµ‹è¯•å‰å‘ä¼ æ’­:")
    test_input = torch.randn(2, 3, 384, 384)
    
    depth_features, depth_map = encoder(test_input)
    
    print(f"è¾“å…¥å½¢çŠ¶: {test_input.shape}")
    print(f"æ·±åº¦ç‰¹å¾å½¢çŠ¶: {depth_features.shape}")
    print(f"æ·±åº¦å›¾å½¢çŠ¶: {depth_map.shape}")
    
    # æµ‹è¯•CLS tokenå’Œpatch tokensæå–
    cls_token = encoder.get_cls_token(depth_features)
    patch_tokens = encoder.get_patch_tokens(depth_features)
    print(f"CLS tokenå½¢çŠ¶: {cls_token.shape}")
    print(f"Patch tokenså½¢çŠ¶: {patch_tokens.shape}")
    
    print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")